{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bit34ef27fa136f4cd3bd679e2aa84ca1a2",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Python\n",
    "## Chapter 7 Extracting Information from Text\n",
    "### 1. Information Extraction\n",
    "#### 1.1 Information Extraction Architecture\n",
    "### 2 Chunking\n",
    "#### 2.1 Noun Phrase Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NP the/DT little/JJ yellow/JJ dog/NN)\n  barked/VBD\n  at/IN\n  (NP the/DT cat/NN))\n"
    }
   ],
   "source": [
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),(\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "grammar = r\"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunker = nltk.RegexpParser(grammar)\n",
    "result = chunker.parse(sentence)\n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2 Tag Patterns\n",
    "#### 2.3 Chunking with Regular Expressions\n",
    "#### 2.4 Exploring Text Corpora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(Chunk combined/VBN to/TO achieve/VB)\n(Chunk continue/VB to/TO place/VB)\n(Chunk serve/VB to/TO protect/VB)\n(Chunk wanted/VBD to/TO wait/VB)\n(Chunk allowed/VBN to/TO place/VB)\n(Chunk expected/VBN to/TO become/VB)\n(Chunk expected/VBN to/TO approve/VB)\n(Chunk expected/VBN to/TO make/VB)\n(Chunk intends/VBZ to/TO make/VB)\n(Chunk seek/VB to/TO set/VB)\n(Chunk like/VB to/TO see/VB)\n(Chunk designed/VBN to/TO provide/VB)\n(Chunk get/VB to/TO hear/VB)\n(Chunk expects/VBZ to/TO tell/VB)\n(Chunk expected/VBN to/TO give/VB)\n(Chunk prefer/VB to/TO pay/VB)\n(Chunk required/VBN to/TO obtain/VB)\n(Chunk permitted/VBN to/TO teach/VB)\n(Chunk designed/VBN to/TO reduce/VB)\n"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "def FindChunk(corpus=brown,rule='Chunk:{<V.*><TO><V.*>}'):\n",
    "    chunker = nltk.RegexpParser(rule)\n",
    "    ChunkTag = rule.split(':')[0]\n",
    "    for sent in brown.tagged_sents()[:200]:\n",
    "        tree = chunker.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == ChunkTag:\n",
    "                print(subtree)\n",
    "FindChunk(brown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Chinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NP the/DT)\n  (NP little/JJ)\n  (NP yellow/JJ)\n  (NP dog/NN)\n  barked/VBD\n  at/IN\n  (NP the/DT)\n  (NP cat/NN))\n"
    }
   ],
   "source": [
    "ChinkRule = r'''\n",
    "NP:\n",
    "    {<.*>}\n",
    "    }<VBD|IN>+{\n",
    "'''\n",
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),(\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "chinker = nltk.RegexpParser(ChinkRule)\n",
    "print(chinker.parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Representing Chunks: Tags vs Trees\n",
    "### 3 Developing and Evaluating Chunkers\n",
    "#### 3.1 Reading IOB Format and the CoNLL 2000 Corpus\n",
    "#### 3.2 Simple Evaluation and Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ChunkParse score:\n    IOB Accuracy:  87.7%%\n    Precision:     70.6%%\n    Recall:        67.8%%\n    F-Measure:     69.2%%\n"
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "TestSet = conll2000.chunked_sents('test.txt',chunk_types=['NP'])\n",
    "grammar = r'NP:{<[CDJNP].*>+}'\n",
    "chunker = nltk.RegexpParser(grammar)\n",
    "print(chunker.evaluate(TestSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ChunkParse score:\n    IOB Accuracy:  92.9%%\n    Precision:     79.9%%\n    Recall:        86.8%%\n    F-Measure:     83.2%%\n"
    }
   ],
   "source": [
    "class UnigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self,TrainSet):\n",
    "        TrainData = [[(tag,ChunkTag) for word,tag,ChunkTag in nltk.chunk.tree2conlltags(sent)] for sent in TrainSet]\n",
    "        self.tagger = nltk.UnigramTagger(TrainData)\n",
    "    def parse(self,sentence):\n",
    "        tag = [tag for word,tag in sentence]\n",
    "        ChunkTag = [ChunkTag for tag,ChunkTag in self.tagger.tag(tag)]\n",
    "        ConllTag = [(word,tag,ChunkTag) for ((word,tag),ChunkTag) in zip(sentence,ChunkTag)]\n",
    "        return nltk.chunk.conlltags2tree(ConllTag)\n",
    "TrainSet = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
    "UnigramChunker = UnigramChunker(TrainSet)\n",
    "print(UnigramChunker.evaluate(TestSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Training Classifier-Based Chunkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -1.09861        0.441\n             2          -0.23049        0.942\n             3          -0.14128        0.954\n             4          -0.11146        0.959\n             5          -0.09671        0.961\n             6          -0.08773        0.964\n             7          -0.08154        0.966\n             8          -0.07691        0.968\n             9          -0.07324        0.970\n            10          -0.07021        0.971\n            11          -0.06765        0.972\n            12          -0.06542        0.973\n            13          -0.06347        0.974\n            14          -0.06173        0.975\n            15          -0.06016        0.976\n            16          -0.05874        0.977\n            17          -0.05744        0.977\n            18          -0.05625        0.978\n            19          -0.05515        0.979\n            20          -0.05413        0.979\n            21          -0.05319        0.979\n            22          -0.05230        0.980\n            23          -0.05147        0.980\n            24          -0.05069        0.980\n            25          -0.04996        0.981\n            26          -0.04926        0.981\n            27          -0.04860        0.981\n            28          -0.04798        0.981\n            29          -0.04739        0.981\n            30          -0.04683        0.982\n            31          -0.04629        0.982\n            32          -0.04578        0.982\n            33          -0.04529        0.982\n            34          -0.04482        0.982\n            35          -0.04437        0.982\n            36          -0.04394        0.982\n            37          -0.04352        0.983\n            38          -0.04313        0.983\n            39          -0.04274        0.983\n            40          -0.04237        0.983\n            41          -0.04202        0.983\n            42          -0.04167        0.983\n            43          -0.04134        0.983\n            44          -0.04102        0.983\n            45          -0.04071        0.984\n            46          -0.04040        0.984\n            47          -0.04011        0.984\n            48          -0.03983        0.984\n            49          -0.03955        0.984\n            50          -0.03929        0.984\n            51          -0.03903        0.984\n            52          -0.03878        0.984\n            53          -0.03853        0.984\n            54          -0.03830        0.984\n            55          -0.03806        0.984\n            56          -0.03784        0.984\n            57          -0.03762        0.985\n            58          -0.03740        0.985\n            59          -0.03720        0.985\n            60          -0.03699        0.985\n            61          -0.03679        0.985\n            62          -0.03660        0.985\n            63          -0.03641        0.985\n            64          -0.03623        0.985\n            65          -0.03605        0.985\n            66          -0.03587        0.985\n            67          -0.03570        0.985\n            68          -0.03553        0.985\n            69          -0.03537        0.985\n            70          -0.03520        0.985\n            71          -0.03505        0.985\n            72          -0.03489        0.985\n            73          -0.03474        0.985\n            74          -0.03459        0.985\n            75          -0.03445        0.985\n            76          -0.03430        0.986\n            77          -0.03416        0.986\n            78          -0.03403        0.986\n            79          -0.03389        0.986\n            80          -0.03376        0.986\n            81          -0.03363        0.986\n            82          -0.03351        0.986\n            83          -0.03338        0.986\n            84          -0.03326        0.986\n            85          -0.03314        0.986\n            86          -0.03302        0.986\n            87          -0.03290        0.986\n            88          -0.03279        0.986\n            89          -0.03268        0.986\n            90          -0.03257        0.986\n            91          -0.03246        0.986\n            92          -0.03235        0.986\n            93          -0.03225        0.986\n            94          -0.03215        0.986\n            95          -0.03204        0.986\n            96          -0.03194        0.986\n            97          -0.03185        0.986\n            98          -0.03175        0.986\n            99          -0.03166        0.986\n         Final          -0.03156        0.986\nChunkParse score:\n    IOB Accuracy:  95.8%%\n    Precision:     87.9%%\n    Recall:        90.7%%\n    F-Measure:     89.3%%\n"
    }
   ],
   "source": [
    "def ExChunkFea(sentence,i,history):\n",
    "    word,pos = sentence[i]\n",
    "    if i == 0:\n",
    "        PrevWord,PrevPos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        PrevWord,PrevPos = sentence[i-1]\n",
    "    if i == len(sentence)-1:\n",
    "        NextWord,NextPos = \"<END>\", \"<END>\"\n",
    "    else:\n",
    "        NextWord,NextPos = sentence[i+1]\n",
    "    TagsSinceDt = set()\n",
    "    for word,tag in sentence[:i]:\n",
    "        if tag == 'DT':\n",
    "            TagsSinceDt = set()\n",
    "        else:\n",
    "            TagsSinceDt.add(tag)\n",
    "    TagsSinceDt = '+'.join(sorted(TagsSinceDt))\n",
    "    feature = {\n",
    "        'word':word,\n",
    "        'pos':pos,\n",
    "        'PrevPos':PrevPos,\n",
    "        'NextPos':NextPos,\n",
    "        'PrevAndPos':'{}+{}'.format(PrevPos,pos),\n",
    "        'NextAndPos':'{}+{}'.format(pos,NextPos),\n",
    "        'PosSinceDT':TagsSinceDt\n",
    "    }\n",
    "    return feature\n",
    "class ConsecutiveNPChunkTagger(nltk.TaggerI):\n",
    "    def __init__(self,TrainSent):\n",
    "        TrainSet = []\n",
    "        for sent in TrainSent:\n",
    "            history = []\n",
    "            untag = nltk.tag.untag(sent)\n",
    "            for i,(word,tag) in enumerate(sent):\n",
    "                feature = ExChunkFea(untag,i,history)\n",
    "                TrainSet.append((feature,tag))\n",
    "                history.append(tag)\n",
    "        self.classifer = nltk.MaxentClassifier.train(TrainSet)\n",
    "    def tag(self,sentence):\n",
    "        history = []\n",
    "        for i,word in enumerate(sentence):\n",
    "            feature = ExChunkFea(sentence,i,history)\n",
    "            tag = self.classifer.classify(feature)\n",
    "            history.append(tag)\n",
    "        return zip(sentence,history)\n",
    "class ConsecutiveNPChunker(nltk.ChunkParserI):\n",
    "    def __init__(self,TrainSet):\n",
    "        TrainData = [[((word,tag),ChunkTag) for word,tag,ChunkTag in nltk.chunk.tree2conlltags(sent)] for sent in TrainSet]\n",
    "        self.tagger = ConsecutiveNPChunkTagger(TrainData)\n",
    "    def parse(self,sentence):\n",
    "        taggedSent = self.tagger.tag(sentence)\n",
    "        ConllTag = [(word,tag,ChunkTag) for ((word,tag),ChunkTag) in taggedSent]\n",
    "        return nltk.chunk.conlltags2tree(ConllTag)\n",
    "chunker = ConsecutiveNPChunker(TrainSet)\n",
    "print(chunker.evaluate(TestSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Recursion in Linguistic Structure\n",
    "#### 4.1 Building Nested Structure with Cascaded Chunkers\n",
    "#### 4.2 Trees\n",
    "#### 4.3 Tree Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "((Alice )(chased (the rabbit )))"
    }
   ],
   "source": [
    "def traverse(tree):\n",
    "    try:\n",
    "        tree.label()\n",
    "    except AttributeError:\n",
    "        print(tree,end=' ')\n",
    "    else:\n",
    "        print('(',end='')\n",
    "        for child in tree:\n",
    "            traverse(child)\n",
    "        print(')',end='')\n",
    "t = nltk.Tree.fromstring('(S (NP Alice) (VP chased (NP the rabbit)))')\n",
    "traverse(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  The/DT\n  (GPE U.S./NNP)\n  is/VBZ\n  one/CD\n  of/IN\n  the/DT\n  few/JJ\n  industrialized/VBN\n  nations/NNS\n  that/WDT\n  *T*-7/-NONE-\n  does/VBZ\n  n't/RB\n  have/VB\n  a/DT\n  higher/JJR\n  standard/NN\n  of/IN\n  regulation/NN\n  for/IN\n  the/DT\n  smooth/JJ\n  ,/,\n  needle-like/JJ\n  fibers/NNS\n  such/JJ\n  as/IN\n  crocidolite/NN\n  that/WDT\n  *T*-1/-NONE-\n  are/VBP\n  classified/VBN\n  *-5/-NONE-\n  as/IN\n  amphobiles/NNS\n  ,/,\n  according/VBG\n  to/TO\n  (PERSON Brooke/NNP T./NNP Mossman/NNP)\n  ,/,\n  a/DT\n  professor/NN\n  of/IN\n  pathlogy/NN\n  at/IN\n  the/DT\n  (ORGANIZATION University/NNP)\n  of/IN\n  (PERSON Vermont/NNP College/NNP)\n  of/IN\n  (GPE Medicine/NNP)\n  ./.)\n"
    }
   ],
   "source": [
    "sent = nltk.corpus.treebank.tagged_sents()[22]\n",
    "print(nltk.ne_chunk(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"
    }
   ],
   "source": [
    "INrule = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
    "    for rel in nltk.sem.extract_rels('ORG','LOC',doc,corpus='ieer',pattern=INrule):\n",
    "        print(nltk.sem.rtuple(rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Summary\n",
    "### 8. Further Reading\n",
    "### 9. Exercises\n",
    "#### 1. The IOB format categorizes tagged tokens as I, O and B. Why are three tags necessary? What problem would be caused if we used I and O tags exclusively?\n",
    "#### 2. Write a tag pattern to match noun phrases containing plural head nouns, e.g. \"many/JJ researchers/NNS\", \"two/CD weeks/NNS\", \"both/DT new/JJ positions/NNS\". Try to do this by generalizing the tag pattern that handled singular noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NPP these/DT little/JJ yellow/JJ dogs/NNS)\n  barked/VBD\n  at/IN\n  the/DT\n  cat/NN)\n"
    }
   ],
   "source": [
    "PluralRule = 'NPP:{<DT>?<CD>?<JJ>*<NNS>}'\n",
    "sentence = [(\"these\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),(\"dogs\", \"NNS\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "chunker = nltk.RegexpParser(PluralRule)\n",
    "print(chunker.parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pick one of the three chunk types in the CoNLL corpus. Inspect the CoNLL corpus and try to observe any patterns in the POS tag sequences that make up this kind of chunk. Develop a simple chunker using the regular expression chunker nltk.RegexpParser. Discuss any tag sequences that are difficult to chunk reliably.\n",
    "#### 4. An early definition of chunk was the material that occurs between chinks. Develop a chunker that starts by putting the whole sentence in a single chunk, and then does the rest of its work solely by chinking. Determine which tags (or tag sequences) are most likely to make up chinks with the help of your own utility program. Compare the performance and simplicity of this approach relative to a chunker based entirely on chunk rules.\n",
    "#### 5. Write a tag pattern to cover noun phrases that contain gerunds, e.g. \"the/DT receiving/VBG end/NN\", \"assistant/NN managing/VBG editor/NN\". Add these patterns to the grammar, one per line. Test your work using some tagged sentences of your own devising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S He/PRP is/VBZ (NPG an/DT assistant/NN managing/VBG editor/NN))\n"
    }
   ],
   "source": [
    "GerundRule = 'NPG:{<DT>?<NN>?<VBG>+<NN>}'\n",
    "sentence = 'He is an assistant managing editor'\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "tagged = [('He', 'PRP'),('is', 'VBZ'),('an', 'DT'),('assistant', 'NN'),('managing', 'VBG'),('editor', 'NN')]\n",
    "chunker = nltk.RegexpParser(GerundRule)\n",
    "print(chunker.parse(tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Write one or more tag patterns to handle coordinated noun phrases, e.g. \"July/NNP and/CC August/NNP\", \"all/DT your/PRP$ managers/NNS and/CC supervisors/NNS\", \"company/NN courts/NNS and/CC adjudicators/NNS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S (NPC July/NNP and/CC August/NNP))\n"
    }
   ],
   "source": [
    "CordRule = 'NPC:{<DT>?<N.*><CC><DT>?<N.*>}'\n",
    "sentence = \"July/NNP and/CC August/NNP\"\n",
    "tagged = [nltk.str2tuple(i) for i in sentence.split()]\n",
    "chunker = nltk.RegexpParser(CordRule)\n",
    "print(chunker.parse(tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Carry out the following evaluation tasks for any of the chunkers you have developed earlier. (Note that most chunking corpora contain some internal inconsistencies, such that any reasonable rule-based approach will produce errors.)\n",
    "##### a. Evaluate your chunker on 100 sentences from a chunked corpus, and report the precision, recall and F-measure.\n",
    "##### b. Use the `chunkscore.missed()` and `chunkscore.incorrect()` methods to identify the errors made by your chunker. Discuss.\n",
    "##### c. Compare the performance of your chunker to the baseline chunker discussed in the evaluation section of this chapter.\n",
    "#### 8. Develop a chunker for one of the chunk types in the CoNLL corpus using a regular-expression based chunk grammar RegexpChunk. Use any combination of rules for chunking, chinking, merging or splitting.\n",
    "#### 9. Sometimes a word is incorrectly tagged, e.g. the head noun in \"12/CD or/CC so/RB cases/VBZ\". Instead of requiring manual correction of tagger output, good chunkers are able to work with the erroneous output of taggers. Look for other examples of correctly chunked noun phrases with incorrect tags.\n",
    "#### 10. The bigram chunker scores about 90% accuracy. Study its errors and try to work out why it doesn't get 100% accuracy. Experiment with trigram chunking. Are you able to improve the performance any more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ChunkParse score:\n    IOB Accuracy:  93.3%%\n    Precision:     82.5%%\n    Recall:        86.8%%\n    F-Measure:     84.6%%\n"
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "class TrigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self,TrainSet):\n",
    "        TrainData = [[(tag,ChunkTag) for word,tag,ChunkTag in nltk.chunk.tree2conlltags(sent)] for sent in TrainSet]\n",
    "        self.tagger = nltk.TrigramTagger(TrainData)\n",
    "    def parse(self,sentence):\n",
    "        tag = [tag for word,tag in sentence]\n",
    "        ChunkTag = [ChunkTag for tag,ChunkTag in self.tagger.tag(tag)]\n",
    "        ConllTag = [(word,tag,ChunkTag) for ((word,tag),ChunkTag) in zip(sentence,ChunkTag)]\n",
    "        return nltk.chunk.conlltags2tree(ConllTag)\n",
    "TrainSet = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
    "TrigramChunker = TrigramChunker(TrainSet)\n",
    "print(UnigramChunker.evaluate(TestSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Apply the n-gram and Brill tagging methods to IOB chunk tagging. Instead of assigning POS tags to words, here we will assign IOB tags to the POS tags. E.g. if the tag DT (determiner) often occurs at the start of a chunk, it will be tagged B (begin). Evaluate the performance of these chunking methods relative to the regular expression chunking methods covered in this chapter.\n",
    "#### 12. We saw in 5. that it is possible to establish an upper limit to tagging performance by looking for ambiguous n-grams, n-grams that are tagged in more than one possible way in the training data. Apply the same method to determine an upper bound on the performance of an n-gram chunker.\n",
    "#### 13. Pick one of the three chunk types in the CoNLL corpus. Write functions to do the following tasks for your chosen type:\n",
    "##### a. List all the tag sequences that occur with each instance of this chunk type.\n",
    "##### b. Count the frequency of each tag sequence, and produce a ranked list in order of decreasing frequency; each line should consist of an integer (the frequency) and the tag sequence.\n",
    "##### c. Inspect the high-frequency tag sequences. Use these as the basis for developing a better chunker.\n",
    "#### 14. The baseline chunker presented in the evaluation section tends to create larger chunks than it should. For example, the phrase: `[every/DT time/NN] [she/PRP] sees/VBZ [a/DT newspaper/NN]` contains two consecutive chunks, and our baseline chunker will incorrectly combine the first two: `[every/DT time/NN she/PRP]`. Write a program that finds which of these chunk-internal tags typically occur at the start of a chunk, then devise one or more rules that will split up these chunks. Combine these with the existing baseline chunker and re-evaluate it, to see if you have discovered an improved baseline.\n",
    "#### 15. Develop an NP chunker that converts POS-tagged text into a list of tuples, where each tuple consists of a verb followed by a sequence of noun phrases and prepositions, e.g. the little cat sat on the mat becomes `('sat', 'on', 'NP')`...\n",
    "#### 16. The Penn Treebank contains a section of tagged Wall Street Journal text that has been chunked into noun phrases. The format uses square brackets, and we have encountered it several times during this chapter. The Treebank corpus can be accessed using: for sent in `nltk.corpus.treebank_chunk.chunked_sents(fileid)`. These are flat trees, just as we got using `nltk.corpus.conll2000.chunked_sents()`.\n",
    "##### a. The functions `nltk.tree.pprint()` and `nltk.chunk.tree2conllstr()` can be used to create Treebank and IOB strings from a tree. Write functions `chunk2brackets()` and `chunk2iob()` that take a single chunk tree as their sole argument, and return the required multi-line string representation.\n",
    "##### b. Write command-line conversion utilities `bracket2iob.py` and `iob2bracket.py` that take a file in Treebank or CoNLL format (resp) and convert it to the other format. (Obtain some raw Treebank or CoNLL data from the NLTK Corpora, save it to a file, and then use `for line in open(filename)` to access it from Python.)\n",
    "#### 17. An n-gram chunker can use information other than the current part-of-speech tag and the n-1 previous chunk tags. Investigate other models of the context, such as the n-1 previous part-of-speech tags, or some combination of previous chunk tags along with previous and following part-of-speech tags.\n",
    "#### 18. Consider the way an n-gram tagger uses recent tags to inform its tagging choice. Now observe how a chunker may re-use this sequence information. For example, both tasks will make use of the information that nouns tend to follow adjectives (in English). It would appear that the same information is being maintained in two places. Is this likely to become a problem as the size of the rule sets grows? If so, speculate about any ways that this problem might be addressed."
   ]
  }
 ]
}