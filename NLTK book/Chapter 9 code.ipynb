{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b67a93151de190f6cc8f9707f54bafc2958bf8bfaa7d847c8c4b5621a84335b3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Natural Language Processing with Python\n",
    "## Chapter 9 Building Feature Based Grammars\n",
    "### 1. Grammatical Features\n",
    "#### 1.1 Syntactic Agreement\n",
    "#### 1.2 Using Attributes and Constraints"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "|.Kim .like.chil.|\nLeaf Init Rule:\n|[----]    .    .| [0:1] 'Kim'\n|.    [----]    .| [1:2] 'likes'\n|.    .    [----]| [2:3] 'children'\nFeature Bottom Up Predict Combine Rule:\n|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\nFeature Bottom Up Predict Combine Rule:\n|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\nFeature Bottom Up Predict Combine Rule:\n|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\nFeature Bottom Up Predict Combine Rule:\n|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\nFeature Bottom Up Predict Combine Rule:\n|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\nFeature Bottom Up Predict Combine Rule:\n|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\nFeature Bottom Up Predict Combine Rule:\n|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\nFeature Bottom Up Predict Combine Rule:\n|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\nFeature Single Edge Fundamental Rule:\n|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\nFeature Single Edge Fundamental Rule:\n|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n(S[]\n  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n  (VP[NUM='sg', TENSE='pres']\n    (TV[NUM='sg', TENSE='pres'] likes)\n    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
    }
   ],
   "source": [
    "tokens = 'Kim likes children'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/feat0.fcfg',trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "source": [
    "#### 1.3 Terminology\n",
    "### 2. Processing Feature Structures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ GND = 'fem' ]\n[ NUM = 'pl'  ]\n[ PER = 3     ]\n[       [ GND = 'fem' ] ]\n[ AGR = [ NUM = 'pl'  ] ]\n[       [ PER = 3     ] ]\n[                       ]\n[ POS = 'N'             ]\n"
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(PER=3, NUM='pl', GND='fem')\n",
    "fs2 = nltk.FeatStruct(AGR=fs1,POS='N')\n",
    "print(fs1)\n",
    "print(fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ A = 'a'             ]\n[                     ]\n[ B = (1) [ C = 'c' ] ]\n[                     ]\n[ D -> (1)            ]\n[ E -> (1)            ]\n"
    }
   ],
   "source": [
    "print(nltk.FeatStruct(\"[A='a', B=(1)[C='c'], D->(1), E->(1)]\"))"
   ]
  },
  {
   "source": [
    "#### 2.1 Subsumption and Unification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ CITY   = 'Paris'      ]\n[ NUMBER = 74           ]\n[ STREET = 'rue Pascal' ]\n"
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(NUMBER=74, STREET='rue Pascal')\n",
    "fs2 = nltk.FeatStruct(CITY='Paris')\n",
    "print(fs1.unify(fs2))"
   ]
  },
  {
   "source": [
    "### 3. Extending a Feature based Grammar\n",
    "#### 3.1 Subcategorization\n",
    "#### 3.2 Heads Revisited\n",
    "#### 3.3 Auxiliary Verbs and Inversion\n",
    "#### 3.4 Unbounded Dependency Constructions\n",
    "#### 3.5 Case and Gender in German\n",
    "### 4. Summary\n",
    "### 5。Further Reading\n",
    "### 6. Exercises\n",
    "#### 1. What constraints are required to correctly parse word sequences like I am happy and she is happy but not *you is happy or *they am happy? Implement two solutions for the present tense paradigm of the verb be in English, first taking Grammar (6) as your starting point, and then taking Grammar (18) as the starting point."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S -> NP_SG VP_SG\n",
    "S -> NP_PL VP_PL\n",
    "NP_SG -> Det_SG N_SG\n",
    "NP_PL -> Det_PL N_PL\n",
    "VP_SG -> V_SG\n",
    "VP_PL -> V_PL\n",
    "\n",
    "Det_SG -> 'this'\n",
    "Det_PL -> 'these'\n",
    "N_SG -> 'dog'\n",
    "N_PL -> 'dogs'\n",
    "V_SG -> 'is'\n",
    "V_PL -> 'are'"
   ]
  },
  {
   "source": [
    "#### 2. ☼ Develop a variant of grammar in 1.1 that uses a feature count to make the distinctions shown below:\t  \t\n",
    "a.    \n",
    "The boy sings.       \n",
    "b.\t\t      \n",
    "*Boy sings.     \n",
    "\n",
    "a.\t\t    \n",
    "The boys sing.        \n",
    "b.\t\t    \n",
    "Boys sing.     \n",
    "\n",
    "a.\t\t    \n",
    "The boys sing.    \n",
    "b.\t\t    \n",
    "Boys sing.\t   \n",
    "   \t\n",
    "a.\t\t  \n",
    "The water is precious.  \n",
    "b.\t\t  \n",
    "Water is precious.\n",
    "#### 3. Write a function `subsumes()` which holds of two feature structures `fs1` and `fs2` just in case `fs1` subsumes `fs2`.\n",
    "#### 4. Modify the grammar illustrated in (28) to incorporate a bar feature for dealing with phrasal projections.\n",
    "#### 5. Modify the German grammar in 3.2 to incorporate the treatment of subcategorization presented in 3.\n",
    "#### 6. Develop a feature based grammar that will correctly describe the following Spanish noun phrases:    \n",
    "#### 7. Develop your own version of the EarleyChartParser which only prints a trace if the input sequence fails to parse.\n",
    "#### 8. Consider the feature structures shown in 6.1.\n",
    "```\n",
    "fs1 = nltk.FeatStruct(\"[A = ?x, B= [C = ?x]]\")\n",
    "fs2 = nltk.FeatStruct(\"[B = [D = d]]\")\n",
    "fs3 = nltk.FeatStruct(\"[B = [C = d]]\")\n",
    "fs4 = nltk.FeatStruct(\"[A = (1)[B = b], C->(1)]\")\n",
    "fs5 = nltk.FeatStruct(\"[A = (1)[D = ?x], C = [E -> (1), F = ?x] ]\")\n",
    "fs6 = nltk.FeatStruct(\"[A = [D = d]]\")\n",
    "fs7 = nltk.FeatStruct(\"[A = [D = d], C = [F = [D = d]]]\")\n",
    "fs8 = nltk.FeatStruct(\"[A = (1)[D = ?x, G = ?x], C = [B = ?x, E -> (1)] ]\")\n",
    "fs9 = nltk.FeatStruct(\"[A = [B = b], C = [E = [G = e]]]\")\n",
    "fs10 = nltk.FeatStruct(\"[A = (1)[B = b], C -> (1)]\")\n",
    "```\n",
    "Example 6.1 (code_featstructures.py): Figure 6.1: Exploring Feature Structures   \n",
    "Work out on paper what the result is of the following unifications. (Hint: you might find it useful to draw the graph structures.)  \n",
    "`fs1` and `fs2`  \n",
    "`fs1` and `fs3`  \n",
    "`fs4` and `fs5`   \n",
    "`fs5` and `fs6`  \n",
    "`fs5` and `fs7`  \n",
    "`fs8` and `fs9`  \n",
    "`fs8` and `fs10`  \n",
    "Check your answers using Python.\n",
    "#### 9. List two feature structures that subsume [A=?x, B=?x].\n",
    "#### 10. Ignoring structure sharing, give an informal algorithm for unifying two feature structures.\n",
    "#### 11. Extend the German grammar in 3.2 so that it can handle so-called verb-second structures like the following:   \t\t\n",
    "Heute sieht der Hund die Katze.\n",
    "#### 12. Seemingly synonymous verbs have slightly different syntactic properties (Levin, 1993). Consider the patterns of grammaticality for the verbs loaded, filled, and dumped below. Can you write grammar productions to handle such data?  \t\t\n",
    "a.\t\t\n",
    "The farmer loaded the cart with sand\n",
    "\n",
    "b.\t\t\n",
    "The farmer loaded sand into the cart\n",
    "\n",
    "c.\t\t\n",
    "The farmer filled the cart with sand\n",
    "\n",
    "d.\t\t\n",
    "*The farmer filled sand into the cart\n",
    "\n",
    "e.\t\t\n",
    "*The farmer dumped the cart with sand\n",
    "\n",
    "f.\t\t\n",
    "The farmer dumped sand into the cart\n",
    "#### 13. Morphological paradigms are rarely completely regular, in the sense of every cell in the matrix having a different realization. For example, the present tense conjugation of the lexeme walk only has two distinct forms: walks for the 3rd person singular, and walk for all other combinations of person and number. A successful analysis should not require redundantly specifying that 5 out of the 6 possible morphological combinations have the same realization. Propose and implement a method for dealing with this.\n",
    "#### 14. So-called head features are shared between the parent node and head child. For example, `TENSE` is a head feature that is shared between a `VP` and its head `V` child. See (Gazdar, Klein, & and, 1985) for more details. Most of the features we have looked at are head features — exceptions are `SUBCAT` and `SLASH`. Since the sharing of head features is predictable, it should not need to be stated explicitly in the grammar productions. Develop an approach that automatically accounts for this regular behavior of head features.\n",
    "#### 15. Extend NLTK's treatment of feature structures to allow unification into list-valued features, and use this to implement an HPSG-style analysis of subcategorization, whereby the `SUBCAT` of a head category is the concatenation its complements' categories with the `SUBCAT` value of its immediate parent.\n",
    "#### 16. Extend NLTK's treatment of feature structures to allow productions with underspecified categories, such as `S[-INV] --> ?x S/?x`.\n",
    "#### 17. Extend NLTK's treatment of feature structures to allow typed feature structures.\n",
    "#### 18. Pick some grammatical constructions described in (Huddleston & Pullum, 2002), and develop a feature based grammar to account for them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}