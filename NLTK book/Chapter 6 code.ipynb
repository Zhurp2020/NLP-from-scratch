{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bit34ef27fa136f4cd3bd679e2aa84ca1a2",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Python\n",
    "## Chapter 5 Learning to Classify Text\n",
    "### 1 Supervised Classification\n",
    "#### 1.1 Gender Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7680084745762712\nMost Informative Features\n            last letter: = 'a'            female : male   =     40.5 : 1.0\n            last letter: = 'k'              male : female =     28.9 : 1.0\n            last letter: = 'f'              male : female =     14.6 : 1.0\n            last letter: = 'd'              male : female =     10.0 : 1.0\n            last letter: = 'p'              male : female =      9.9 : 1.0\n            last letter: = 'v'              male : female =      9.2 : 1.0\n            last letter: = 'm'              male : female =      8.5 : 1.0\n            last letter: = 'o'              male : female =      8.2 : 1.0\n            last letter: = 'r'              male : female =      6.4 : 1.0\n            last letter: = 'w'              male : female =      5.9 : 1.0\n"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk \n",
    "import random\n",
    "def ExtractNameFeature(name):\n",
    "    feature = {\n",
    "        'first letter':name[0],\n",
    "        'last letter:':name[-1]\n",
    "    }\n",
    "    return feature\n",
    "LabeledNames = [(i,'male') for i in names.words('male.txt')] + [(i,'female') for i in names.words('female.txt')]\n",
    "random.shuffle(LabeledNames)\n",
    "FeatureList = [(ExtractNameFeature(i[0]),i[1]) for i in LabeledNames]\n",
    "TrainSet,TestSet = FeatureList[:7000],FeatureList[7000:]\n",
    "GenderClassifier = nltk.NaiveBayesClassifier.train(TrainSet)\n",
    "print(nltk.classify.accuracy(GenderClassifier,TestSet))\n",
    "GenderClassifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Choosing The Right Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.766\nBess correct: female wrong male\nMarsh correct: male wrong female\nElizabet correct: female wrong male\nVivian correct: female wrong male\nGranville correct: male wrong female\nArvin correct: male wrong female\nHedwig correct: female wrong male\nOrville correct: male wrong female\nArne correct: male wrong female\nTyrone correct: male wrong female\nMaurice correct: male wrong female\nKip correct: female wrong male\nSully correct: male wrong female\nClemente correct: male wrong female\nGarey correct: male wrong female\nDuffie correct: male wrong female\nLarry correct: male wrong female\nBo correct: female wrong male\nTansy correct: female wrong male\nTrixy correct: female wrong male\nRobinett correct: female wrong male\nRiannon correct: female wrong male\nCammy correct: male wrong female\nSinead correct: female wrong male\nAddie correct: male wrong female\nLynn correct: male wrong female\nChris correct: female wrong male\nLonny correct: male wrong female\nVirge correct: male wrong female\nWynn correct: female wrong male\nPenny correct: female wrong male\nGillan correct: female wrong male\nLawson correct: male wrong female\nKurtis correct: male wrong female\nAntoni correct: male wrong female\nAstrid correct: female wrong male\nGabriell correct: female wrong male\nBrear correct: female wrong male\nJason correct: male wrong female\nAntony correct: male wrong female\nHyacinth correct: female wrong male\nShir correct: female wrong male\nRuddy correct: male wrong female\nGail correct: female wrong male\nKeith correct: male wrong female\nDemetri correct: male wrong female\nBrook correct: female wrong male\nGarvy correct: male wrong female\nAntoine correct: male wrong female\nKim correct: female wrong male\nLemmy correct: male wrong female\nGeorge correct: male wrong female\nKurt correct: male wrong female\nFleur correct: female wrong male\nBlare correct: male wrong female\nGredel correct: female wrong male\nMorton correct: male wrong female\nMaxwell correct: male wrong female\nHelen correct: female wrong male\nViolet correct: female wrong male\nKory correct: male wrong female\nMerry correct: male wrong female\nKlaus correct: male wrong female\nNikita correct: male wrong female\nMillisent correct: female wrong male\nSybyl correct: female wrong male\nGweneth correct: female wrong male\nJoaquin correct: male wrong female\nPhyllis correct: female wrong male\nDevon correct: male wrong female\nRawley correct: male wrong female\nDani correct: male wrong female\nSheilakathryn correct: female wrong male\nJeremy correct: male wrong female\nMarten correct: male wrong female\nMahesh correct: male wrong female\nKristos correct: male wrong female\nUli correct: male wrong female\nFrank correct: female wrong male\nTuesday correct: female wrong male\nAguste correct: male wrong female\nVan correct: female wrong male\nRachel correct: female wrong male\nWinnie correct: female wrong male\nWally correct: female wrong male\nDavide correct: male wrong female\nSharyl correct: female wrong male\nAnatoly correct: male wrong female\nDamaris correct: female wrong male\nMarys correct: female wrong male\nKalman correct: male wrong female\nMattie correct: male wrong female\nNeall correct: male wrong female\nAngel correct: male wrong female\nTrix correct: female wrong male\nLawton correct: male wrong female\nHercule correct: male wrong female\nBeret correct: female wrong male\nKoo correct: female wrong male\nLouie correct: male wrong female\nDarby correct: male wrong female\nAshby correct: male wrong female\nBernie correct: male wrong female\nShayne correct: male wrong female\nNevil correct: male wrong female\nLaurie correct: male wrong female\nKarsten correct: male wrong female\nRandie correct: male wrong female\nShell correct: female wrong male\nGretel correct: female wrong male\nJoel correct: male wrong female\nAlyss correct: female wrong male\nDarcy correct: male wrong female\nPierce correct: male wrong female\nMuffin correct: male wrong female\nBarclay correct: male wrong female\nElwyn correct: male wrong female\nIngeborg correct: female wrong male\nNinon correct: female wrong male\nRoseann correct: female wrong male\nVite correct: male wrong female\nJosiah correct: male wrong female\nJohn correct: male wrong female\nSunny correct: male wrong female\nBrit correct: female wrong male\nSydney correct: male wrong female\nEsme correct: male wrong female\nErvin correct: male wrong female\nPerl correct: female wrong male\nJanifer correct: female wrong male\nKendal correct: male wrong female\nOsbourne correct: male wrong female\nAgamemnon correct: male wrong female\nLeroy correct: male wrong female\nMika correct: male wrong female\nStearne correct: male wrong female\nHarmony correct: female wrong male\nKelvin correct: male wrong female\nClarke correct: male wrong female\nTimothee correct: male wrong female\nHannah correct: female wrong male\nHoney correct: female wrong male\nHedy correct: female wrong male\nRhianon correct: female wrong male\nElwin correct: male wrong female\nElmore correct: male wrong female\nDaren correct: male wrong female\nNoelyn correct: female wrong male\nLilas correct: female wrong male\nEmmanuel correct: male wrong female\nKyle correct: male wrong female\nObadiah correct: male wrong female\nGen correct: female wrong male\nBradly correct: male wrong female\nSterne correct: male wrong female\nCole correct: male wrong female\nRuthann correct: female wrong male\nSammie correct: male wrong female\nCat correct: female wrong male\nRahel correct: female wrong male\nAmory correct: male wrong female\nBill correct: female wrong male\nLaurance correct: male wrong female\nFonsie correct: male wrong female\nLawrence correct: male wrong female\nBev correct: female wrong male\nLee correct: male wrong female\nSher correct: female wrong male\nJess correct: female wrong male\nGiovanni correct: male wrong female\nBidget correct: female wrong male\nBeitris correct: female wrong male\nAmargo correct: female wrong male\nJohnathan correct: male wrong female\nGarry correct: male wrong female\nLyndon correct: male wrong female\nAverell correct: male wrong female\nPatty correct: female wrong male\nDryke correct: male wrong female\nLlewellyn correct: male wrong female\nMelisent correct: female wrong male\nBrinkley correct: male wrong female\nSansone correct: male wrong female\nClem correct: female wrong male\nPegeen correct: female wrong male\nDunstan correct: male wrong female\nLesley correct: male wrong female\nVeradis correct: female wrong male\nTamar correct: female wrong male\nConnolly correct: male wrong female\nJuliet correct: female wrong male\nKostas correct: male wrong female\nIzabel correct: female wrong male\nCecil correct: male wrong female\nFranky correct: male wrong female\nWaly correct: female wrong male\nKarel correct: male wrong female\nSybil correct: female wrong male\nGennifer correct: female wrong male\nBradley correct: male wrong female\nPrince correct: male wrong female\nConroy correct: male wrong female\nJesse correct: male wrong female\nAdrian correct: male wrong female\nMairead correct: female wrong male\nLefty correct: male wrong female\nAlfie correct: male wrong female\nAsh correct: male wrong female\nZarah correct: female wrong male\nBrigid correct: female wrong male\nVirgil correct: male wrong female\nAnatole correct: male wrong female\nDonovan correct: male wrong female\nAmbur correct: female wrong male\nMaddy correct: male wrong female\nFiann correct: female wrong male\nMerle correct: male wrong female\nDion correct: male wrong female\nCarleigh correct: male wrong female\nBeilul correct: female wrong male\nFrancis correct: female wrong male\nShirleen correct: female wrong male\nTre correct: male wrong female\nWynny correct: female wrong male\nDawson correct: male wrong female\nSergei correct: male wrong female\nBrooke correct: male wrong female\nVal correct: male wrong female\nGrissel correct: female wrong male\nTome correct: male wrong female\nLuke correct: male wrong female\nTierney correct: female wrong male\nCass correct: female wrong male\nLeland correct: female wrong male\n"
    }
   ],
   "source": [
    "TrainSet,DevTestSet,TestSet = LabeledNames[:6000],LabeledNames[6000:7000],LabeledNames[7000:]\n",
    "GenderClassifier = nltk.NaiveBayesClassifier.train([(ExtractNameFeature(i[0]),i[1]) for i in TrainSet])\n",
    "print(nltk.classify.accuracy(GenderClassifier,[(ExtractNameFeature(i[0]),i[1]) for i in DevTestSet]))\n",
    "for name in DevTestSet:\n",
    "    result = GenderClassifier.classify(ExtractNameFeature(name[0])) \n",
    "    if result != name[1] :\n",
    "        print(name[0],'correct:',name[1],'wrong',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.81\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('contains outstanding', True),\n ('contains mulan', True),\n ('contains wonderfully', True),\n ('contains seagal', True),\n ('contains damon', True),\n ('contains poorly', True),\n ('contains flynt', True),\n ('contains ridiculous', True),\n ('contains lame', True),\n ('contains wasted', True),\n ('contains awful', True),\n ('contains waste', True),\n ('contains era', True),\n ('contains pointless', True),\n ('contains sandler', True),\n ('contains unfunny', True),\n ('contains laughable', True),\n ('contains dull', True),\n ('contains worst', True),\n ('contains fantastic', True),\n ('contains allows', True),\n ('contains mess', True),\n ('contains boring', True),\n ('contains bland', True),\n ('contains jedi', True),\n ('contains superb', True),\n ('contains stupid', True),\n ('contains terrific', True),\n ('contains portrayal', True),\n ('contains memorable', True),\n ('contains zero', True),\n ('contains snake', True),\n ('contains masterpiece', True),\n ('contains terrible', True),\n ('contains badly', True),\n ('contains excellent', True),\n ('contains patch', True),\n ('contains subtle', True),\n ('contains portrayed', True),\n ('contains clich', True),\n ('contains perfectly', True),\n ('contains naked', True),\n ('contains hanks', True),\n ('contains flaws', True),\n ('contains natural', True),\n ('contains realistic', True),\n ('contains tony', True),\n ('contains lucas', True),\n ('contains brilliant', True),\n ('contains political', True),\n ('contains animation', True),\n ('contains helps', True),\n ('contains effective', True),\n ('contains issues', True),\n ('contains cheesy', True),\n ('contains visually', True),\n ('contains dumb', True),\n ('contains period', True),\n ('contains share', True),\n ('contains complex', True),\n ('contains gags', True),\n ('contains remake', True),\n ('contains fascinating', True),\n ('contains quiet', True),\n ('contains wonderful', True),\n ('contains sub', True),\n ('contains deserves', True),\n ('contains remarkable', True),\n ('contains succeeds', True),\n ('contains fails', True),\n ('contains porn', True),\n ('contains spice', True),\n ('contains history', True),\n ('contains failure', True),\n ('contains cameron', True),\n ('contains strength', True),\n ('contains damme', True),\n ('contains normal', True),\n ('contains emotionally', True),\n ('contains stunning', True),\n ('contains blame', True),\n ('contains unless', True),\n ('contains touching', True),\n ('contains batman', True),\n ('contains in', False),\n ('contains woo', True),\n ('contains spielberg', True),\n ('contains epic', True),\n ('contains perfect', True),\n ('contains powerful', True),\n ('contains julie', True),\n ('contains teacher', True),\n ('contains themes', True),\n ('contains supposed', True),\n ('contains mood', True),\n ('contains intense', True),\n ('contains hilarious', True),\n ('contains rare', True),\n ('contains minute', True),\n ('contains sadly', True)]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "docs = [(list(movie_reviews.words(fileid)),category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(docs)\n",
    "WordFeature = list(nltk.FreqDist([w.lower() for w in movie_reviews.words()]))[:2000]\n",
    "def ExDocFeature(doc):\n",
    "    words = set(doc)\n",
    "    features = {}\n",
    "    for i in WordFeature:\n",
    "        features['contains {}'.format(i)] = i in words\n",
    "    return features\n",
    "DocFeaList = [(ExDocFeature(doc),c) for (doc,c) in docs]\n",
    "TrainSet,TestSet = DocFeaList[:1800],DocFeaList[1800:]\n",
    "DocClassifier = nltk.NaiveBayesClassifier.train(TrainSet)\n",
    "print(nltk.classify.accuracy(DocClassifier,TestSet))\n",
    "DocClassifier.most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6262080727686186\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"if endswith the == False: \\n  if endswith , == False: \\n    if endswith s == False: \\n      if endswith . == False: return 'AT'\\n      if endswith . == True: return '.'\\n    if endswith s == True: \\n      if endswith was == False: return 'VBZ'\\n      if endswith was == True: return 'BEDZ'\\n  if endswith , == True: return ','\\nif endswith the == True: return 'AT'\\n\""
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "SuffixFD = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    SuffixFD[word[-1]] += 1\n",
    "    SuffixFD[word[-2:]] += 1\n",
    "    SuffixFD[word[-3:]] += 1\n",
    "CommonSuffix = [i[0] for i in SuffixFD.most_common(100)]\n",
    "def ExPosFea(word):\n",
    "    feature = {}\n",
    "    for i in CommonSuffix:\n",
    "        feature['endswith {}'.format(i)] = word.lower().endswith(i)\n",
    "    return feature\n",
    "TaggedWords = brown.tagged_words(categories='news')\n",
    "PosFeaList = [(ExPosFea(n),g) for (n,g) in TaggedWords]\n",
    "TrainSet,TestSet = PosFeaList[:90000],PosFeaList[90000:]\n",
    "PoSClassifier = nltk.DecisionTreeClassifier.train(TrainSet)\n",
    "print(nltk.classify.accuracy(PoSClassifier,TestSet))\n",
    "PoSClassifier.pseudocode(depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Exploiting Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7774303581580443"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "def ExPosConFeature(sentence,i):\n",
    "    feature = {\n",
    "        'suffix1':sentence[i][-1],\n",
    "        'suffix2':sentence[i][-2:],\n",
    "        'suffix3':sentence[i][-3:]\n",
    "    }\n",
    "    if i == 0:\n",
    "        feature['PrevWord'] = '<START>'\n",
    "    else:\n",
    "        feature['PrevWord'] = sentence[i-1]\n",
    "    return feature\n",
    "BTaggedSent = brown.tagged_sents(categories='news')\n",
    "SentFeaList = []\n",
    "for sent in BTaggedSent:\n",
    "    untag = nltk.tag.untag(sent)\n",
    "    for i,(word,tag) in enumerate(sent):\n",
    "        SentFeaList.append((ExPosConFeature(untag,i),tag))\n",
    "TrainSet,TestSet = SentFeaList[:90000],SentFeaList[90000:]\n",
    "PosConClassifier = nltk.NaiveBayesClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(PosConClassifier,TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7782902322516884"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "def ExPosHisFea(sentence,i,history):\n",
    "    feature = {\n",
    "        'suffix1':sentence[i][-1],\n",
    "        'suffix2':sentence[i][-2:],\n",
    "        'suffix3':sentence[i][-3:]\n",
    "    }\n",
    "    if i == 0:\n",
    "        feature['PrevWord'] = '<START>'\n",
    "        feature['PrevTag'] = '<START>'\n",
    "    else:\n",
    "        feature['PrevWord'] = sentence[i-1]\n",
    "        feature['PrevTag'] = history[i-1]\n",
    "    return feature \n",
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "    def __init__(self,TrainSent):\n",
    "        TrainList = []\n",
    "        for sent in TrainSet:\n",
    "            untag = nltk.tag.untag(sent)\n",
    "            history = []\n",
    "            for i,(word,tag) in enumerate(sent):\n",
    "                feature = ExPosHisFea(untag,i,history)\n",
    "                TrainList.append((feature,tag))\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(TrainList)\n",
    "    def tag(self,sentence):\n",
    "        history = []\n",
    "        for i,word in enumerate(sentence):\n",
    "            feature = ExPosHisFea(sentence,i,history)\n",
    "            tag = self.classifier.classify(feature)\n",
    "            history.append(tag)\n",
    "        return zip(sentence,history)\n",
    "TrainSet,TestSet = BTaggedSent[:3800],BTaggedSent[3800:]\n",
    "ConsecutiveTagger = ConsecutivePosTagger(TrainSet)\n",
    "ConsecutiveTagger.evaluate(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Other Methods for Sequence Classification\n",
    "### 2. Further Examples of Supervised Classification\n",
    "#### 2.1 Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9578059071729957"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "tokens = list()\n",
    "boundary = set()\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundary.add(offset-1)\n",
    "def ExPunctFea(tokens,i):\n",
    "    feature = {\n",
    "        'next word capitalized':tokens[i+1][0].isupper(),\n",
    "        'prev-word':tokens[i-1].lower(),\n",
    "        'punct':tokens[i], \n",
    "        'prev word one char': len(tokens[i-1]) == 1\n",
    "    }\n",
    "    return feature\n",
    "PunctFeaList = [(ExPunctFea(tokens,i),(i in boundary)) for i in range(1,len(tokens)-1) if tokens[i] in '.?!' ]\n",
    "TrainSet,TestSet = PunctFeaList[:5000],PunctFeaList[5000:]\n",
    "PunctClassifier = nltk.NaiveBayesClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(PunctClassifier,TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Identifying Dialogue Act Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6433333333333333"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:3000]\n",
    "def ExDialogFea(post):\n",
    "    feature = {}\n",
    "    for i in nltk.word_tokenize(post):\n",
    "        feature['contain {}'.format(i.lower())] = True\n",
    "    return feature\n",
    "DialogueFeaList = [(ExDialogFea(post.text),post.get('class')) for post in posts]\n",
    "TrainSet,TestSet = DialogueFeaList[:2700],DialogueFeaList[2700:]\n",
    "DialogueClassifier = nltk.NaiveBayesClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(DialogueClassifier,TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Recognizing Textual Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExRTEFea(pair):\n",
    "    extractor = nltk.RTEFeatureExtractor(pair)\n",
    "    feature = {}\n",
    "    feature['word overlap'] = extractor.overlap('word')\n",
    "    feature['word hyp extra'] = extractor.hyp_extra('word')\n",
    "    feature['ne overlap'] = extractor.overlap('ne')\n",
    "    feature['ne hyp extra'] = extractor.hyp_extra('ne')\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Scaling Up to Large Datasets\n",
    "### 3. Evaluation\n",
    "#### 3.1 The Test Set\n",
    "#### 3.2 Accuracy\n",
    "#### 3.3 Precision and Recall\n",
    "#### 3.4 Confusion Matrices\n",
    "#### 3.5 Cross-Validation\n",
    "### 4. Decision Trees\n",
    "#### 4.1 Entropy and Information Gain\n",
    "### 5. Naive Bayes Classifiers\n",
    "#### 5.1 Underlying Probabilistic Model\n",
    "#### 5.2 Zero Counts and Smoothing\n",
    "#### 5.3 Non-Binary Features\n",
    "#### 5.4 The Naivete of Independence\n",
    "#### 5.5 The Cause of Double-Counting\n",
    "### 6. Maximum Entropy Classifiers\n",
    "#### 6.1 The Maximum Entropy Model\n",
    "#### 6.2 Maximizing Entropy\n",
    "#### 6.3 Generative vs Conditional Classifiers\n",
    "### 7. Modeling Linguistic Patterns\n",
    "#### 7.1 What do models tell us?\n",
    "### 8. Summary\n",
    "### 9. Further Reading\n",
    "### 10. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read up on one of the language technologies mentioned in this section, such as word sense disambiguation, semantic role labeling, question answering, machine translation, named entity detection. Find out what type and quantity of annotated data is required for developing such systems. Why do you think a large amount of data is required?\n",
    "#### 2. Using any of the three classifiers described in this chapter, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "#### 3. The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. It contains data for four words: hard, interest, line, and serve. Choose one of these four words, and load the corresponding data:\n",
    "```\n",
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances('hard.pos')\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, test_set = instances[size:], instances[:size]\n",
    "```\n",
    "Using this dataset, build a classifier that predicts the correct sense tag for a given instance. See the corpus HOWTO at `http://nltk.org/howto` for information on using the instance objects returned by the Senseval 2 Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -1.09861        0.087\n             2          -0.33702        0.800\n             3          -0.31773        0.822\n             4          -0.30403        0.833\n             5          -0.29450        0.841\n             6          -0.28737        0.847\n             7          -0.28178        0.854\n             8          -0.27724        0.854\n             9          -0.27349        0.856\n            10          -0.27034        0.856\n            11          -0.26765        0.856\n            12          -0.26533        0.856\n            13          -0.26331        0.856\n            14          -0.26153        0.856\n            15          -0.25995        0.856\n            16          -0.25855        0.856\n            17          -0.25728        0.856\n            18          -0.25613        0.856\n            19          -0.25509        0.856\n            20          -0.25414        0.856\n            21          -0.25327        0.856\n            22          -0.25247        0.856\n            23          -0.25173        0.856\n            24          -0.25104        0.856\n            25          -0.25040        0.856\n            26          -0.24981        0.856\n            27          -0.24925        0.856\n            28          -0.24873        0.856\n            29          -0.24825        0.856\n            30          -0.24779        0.856\n            31          -0.24735        0.856\n            32          -0.24695        0.856\n            33          -0.24656        0.856\n            34          -0.24619        0.856\n            35          -0.24585        0.856\n            36          -0.24552        0.856\n            37          -0.24520        0.856\n            38          -0.24490        0.856\n            39          -0.24462        0.856\n            40          -0.24435        0.856\n            41          -0.24409        0.856\n            42          -0.24384        0.856\n            43          -0.24360        0.856\n            44          -0.24337        0.856\n            45          -0.24315        0.856\n            46          -0.24294        0.856\n            47          -0.24273        0.856\n            48          -0.24254        0.856\n            49          -0.24235        0.856\n            50          -0.24217        0.856\n            51          -0.24199        0.856\n            52          -0.24183        0.856\n            53          -0.24166        0.856\n            54          -0.24150        0.856\n            55          -0.24135        0.856\n            56          -0.24120        0.856\n            57          -0.24106        0.856\n            58          -0.24092        0.856\n            59          -0.24079        0.856\n            60          -0.24066        0.856\n            61          -0.24053        0.856\n            62          -0.24041        0.856\n            63          -0.24029        0.856\n            64          -0.24017        0.856\n            65          -0.24006        0.856\n            66          -0.23995        0.856\n            67          -0.23984        0.856\n            68          -0.23974        0.856\n            69          -0.23964        0.856\n            70          -0.23954        0.856\n            71          -0.23944        0.856\n            72          -0.23935        0.856\n            73          -0.23926        0.856\n            74          -0.23917        0.856\n            75          -0.23908        0.856\n            76          -0.23900        0.856\n            77          -0.23891        0.856\n            78          -0.23883        0.856\n            79          -0.23875        0.856\n            80          -0.23868        0.856\n            81          -0.23860        0.856\n            82          -0.23853        0.856\n            83          -0.23845        0.856\n            84          -0.23838        0.856\n            85          -0.23831        0.856\n            86          -0.23825        0.856\n            87          -0.23818        0.856\n            88          -0.23811        0.856\n            89          -0.23805        0.856\n            90          -0.23799        0.856\n            91          -0.23792        0.856\n            92          -0.23786        0.855\n            93          -0.23781        0.855\n            94          -0.23775        0.855\n            95          -0.23769        0.855\n            96          -0.23763        0.855\n            97          -0.23758        0.855\n            98          -0.23753        0.855\n            99          -0.23747        0.855\n         Final          -0.23742        0.855\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8142589118198874"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances('hard.pos')\n",
    "def ExInsFea(instance):\n",
    "    feature = {\n",
    "        'tag':instance.context[instance.position][1],\n",
    "        #'position':instance.position\n",
    "    }\n",
    "    if instance.position == 0:\n",
    "        feature['prev-tag'] = '<START>',\n",
    "        feature['prev-word'] = '<START>',\n",
    "        feature['prev-2-tag'] = '<START>',\n",
    "        feature['prev-2-word'] = '<START>'\n",
    "    elif instance.position == 1:\n",
    "        feature['prev-tag'] = instance.context[instance.position-1][1],\n",
    "        feature['prev-word'] = instance.context[instance.position-1][0],\n",
    "        feature['prev-2-tag'] = '<START>',\n",
    "        feature['prev-2-word'] = '<START>'\n",
    "    else:\n",
    "        feature['prev-tag'] = instance.context[instance.position-1][1]\n",
    "        feature['prev-word'] = instance.context[instance.position-1][0]\n",
    "    return feature\n",
    "InsFeaList = [(ExInsFea(instance),instance.senses) for instance in instances]\n",
    "random.shuffle(InsFeaList)\n",
    "TrainSet,TestSet = InsFeaList[:3800],InsFeaList[3800:]\n",
    "InsClassifier = nltk.MaxentClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(InsClassifier,TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Using the movie review document classifier discussed in this chapter, generate a list of the 30 features that the classifier finds to be most informative. Can you explain why these particular features are informative? Do you find any of them surprising?\n",
    "Select one of the classification tasks described in this chapter, such as name gender detection, document classification, part-of-speech tagging, or dialog act classification. #### 5. Using the same training and test data, and the same feature extractor, build three classifiers for the task: a decision tree, a naive Bayes classifier, and a Maximum Entropy classifier. Compare the performance of the three classifiers on your selected task. How do you think that your results might be different if you used a different feature extractor?\n",
    "#### 6. The synonyms strong and powerful pattern differently (try combining them with chip and sales). What features are relevant in this distinction? Build a classifier that predicts when each word should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -0.69315        0.740\n             2          -0.43569        0.780\n             3          -0.37626        0.845\n             4          -0.33564        0.875\n             5          -0.30509        0.930\n             6          -0.28098        0.935\n             7          -0.26137        0.940\n             8          -0.24505        0.945\n             9          -0.23122        0.945\n            10          -0.21935        0.950\n            11          -0.20902        0.950\n            12          -0.19995        0.950\n            13          -0.19192        0.950\n            14          -0.18476        0.950\n            15          -0.17832        0.950\n            16          -0.17250        0.950\n            17          -0.16722        0.955\n            18          -0.16240        0.955\n            19          -0.15798        0.955\n            20          -0.15391        0.955\n            21          -0.15016        0.955\n            22          -0.14668        0.955\n            23          -0.14344        0.955\n            24          -0.14043        0.955\n            25          -0.13761        0.955\n            26          -0.13498        0.955\n            27          -0.13250        0.955\n            28          -0.13018        0.955\n            29          -0.12798        0.955\n            30          -0.12591        0.955\n            31          -0.12395        0.955\n            32          -0.12210        0.955\n            33          -0.12034        0.955\n            34          -0.11866        0.955\n            35          -0.11707        0.955\n            36          -0.11555        0.955\n            37          -0.11411        0.955\n            38          -0.11273        0.955\n            39          -0.11140        0.955\n            40          -0.11014        0.955\n            41          -0.10893        0.955\n            42          -0.10777        0.955\n            43          -0.10665        0.955\n            44          -0.10558        0.955\n            45          -0.10455        0.955\n            46          -0.10356        0.955\n            47          -0.10260        0.955\n            48          -0.10168        0.960\n            49          -0.10079        0.960\n            50          -0.09993        0.960\n            51          -0.09910        0.960\n            52          -0.09830        0.960\n            53          -0.09753        0.960\n            54          -0.09678        0.960\n            55          -0.09605        0.960\n            56          -0.09535        0.960\n            57          -0.09467        0.960\n            58          -0.09401        0.960\n            59          -0.09336        0.960\n            60          -0.09274        0.960\n            61          -0.09213        0.960\n            62          -0.09155        0.960\n            63          -0.09097        0.960\n            64          -0.09042        0.960\n            65          -0.08988        0.960\n            66          -0.08935        0.960\n            67          -0.08884        0.960\n            68          -0.08834        0.960\n            69          -0.08785        0.960\n            70          -0.08737        0.960\n            71          -0.08691        0.960\n            72          -0.08646        0.960\n            73          -0.08602        0.960\n            74          -0.08559        0.960\n            75          -0.08516        0.960\n            76          -0.08475        0.960\n            77          -0.08435        0.960\n            78          -0.08396        0.960\n            79          -0.08357        0.960\n            80          -0.08320        0.960\n            81          -0.08283        0.960\n            82          -0.08247        0.960\n            83          -0.08212        0.960\n            84          -0.08178        0.960\n            85          -0.08144        0.960\n            86          -0.08111        0.960\n            87          -0.08078        0.960\n            88          -0.08047        0.960\n            89          -0.08016        0.960\n            90          -0.07985        0.960\n            91          -0.07955        0.960\n            92          -0.07926        0.960\n            93          -0.07897        0.960\n            94          -0.07869        0.960\n            95          -0.07841        0.960\n            96          -0.07814        0.960\n            97          -0.07787        0.960\n            98          -0.07761        0.960\n            99          -0.07735        0.960\n         Final          -0.07710        0.960\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8421052631578947"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "SynoSent = []\n",
    "SynoSent.append([i for i in brown.tagged_sents() if 'powerful' in [j[0].lower() for j in i]])\n",
    "SynoSent.append([i for i in brown.tagged_sents() if 'strong' in [j[0].lower() for j in i]])\n",
    "def ExSynoFea(sent):\n",
    "    feature = {}\n",
    "    untag = [j[0].lower() for j in sent]\n",
    "    if 'powerful' in untag:\n",
    "        index = untag.index('powerful')\n",
    "    else:\n",
    "        index = untag.index('strong')\n",
    "    if index == 0 :\n",
    "        feature['prev-tag'] = '<START>'\n",
    "        feature['prev-word'] = '<START>'\n",
    "        feature['next-tag'] = sent[1][1]\n",
    "        feature['next-word'] = sent[1][0]\n",
    "    elif index ==  len(sent):\n",
    "        feature['prev-tag'] = sent[-1][1]\n",
    "        feature['prev-word'] = sent[-1][0]\n",
    "        feature['next-tag'] = '<END>'\n",
    "        feature['next-word'] = '<END>'\n",
    "    else:\n",
    "        feature['prev-tag'] = sent[index-1][1]\n",
    "        feature['prev-word'] = sent[index-1][0]\n",
    "        feature['next-tag'] = sent[index+1][1]\n",
    "        feature['next-word'] = sent[index+1][0]\n",
    "    return feature\n",
    "SynoFeaList = []\n",
    "for i in SynoSent[0]:\n",
    "    SynoFeaList.append((ExSynoFea(i),'P'))\n",
    "for i in SynoSent[1]:\n",
    "    SynoFeaList.append((ExSynoFea(i),'S'))\n",
    "random.shuffle(SynoFeaList)\n",
    "TrainSet,TestSet = SynoFeaList[:200],SynoFeaList[200:]\n",
    "SynoClassifier = nltk.MaxentClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(SynoClassifier,TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. The dialog act classifier assigns labels to individual posts, without considering the context in which the post is found. However, dialog acts are highly dependent on context, and some sequences of dialog act are much more likely than others. For example, a `ynQuestion` dialog act is much more likely to be answered by a `yanswer` than by a `greeting`. Make use of this fact to build a consecutive classifier for labeling dialog acts. Be sure to consider what features might be useful. See the code for the consecutive classifier for part-of-speech tags in 1.7 to get some ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -2.70805        0.052\n             2          -1.20576        0.788\n             3          -0.85297        0.828\n             4          -0.68715        0.863\n             5          -0.58516        0.886\n             6          -0.51542        0.901\n             7          -0.46421        0.913\n             8          -0.42467        0.922\n             9          -0.39298        0.929\n            10          -0.36689        0.935\n            11          -0.34494        0.939\n            12          -0.32615        0.942\n            13          -0.30983        0.945\n            14          -0.29551        0.949\n            15          -0.28280        0.950\n            16          -0.27144        0.953\n            17          -0.26120        0.955\n            18          -0.25192        0.956\n            19          -0.24346        0.958\n            20          -0.23571        0.959\n            21          -0.22857        0.961\n            22          -0.22198        0.962\n            23          -0.21587        0.963\n            24          -0.21018        0.964\n            25          -0.20487        0.965\n            26          -0.19990        0.966\n            27          -0.19523        0.966\n            28          -0.19085        0.966\n            29          -0.18672        0.967\n            30          -0.18281        0.968\n            31          -0.17912        0.969\n            32          -0.17561        0.969\n            33          -0.17229        0.970\n            34          -0.16912        0.970\n            35          -0.16611        0.970\n            36          -0.16324        0.971\n            37          -0.16049        0.971\n            38          -0.15787        0.973\n            39          -0.15536        0.973\n            40          -0.15295        0.973\n            41          -0.15064        0.973\n            42          -0.14842        0.974\n            43          -0.14629        0.974\n            44          -0.14423        0.974\n            45          -0.14226        0.974\n            46          -0.14035        0.975\n            47          -0.13851        0.975\n            48          -0.13674        0.975\n            49          -0.13502        0.975\n            50          -0.13337        0.975\n            51          -0.13176        0.976\n            52          -0.13021        0.976\n            53          -0.12871        0.976\n            54          -0.12725        0.977\n            55          -0.12584        0.977\n            56          -0.12447        0.977\n            57          -0.12314        0.977\n            58          -0.12185        0.978\n            59          -0.12059        0.978\n            60          -0.11937        0.978\n            61          -0.11818        0.978\n            62          -0.11702        0.978\n            63          -0.11590        0.979\n            64          -0.11480        0.979\n            65          -0.11373        0.979\n            66          -0.11269        0.979\n            67          -0.11168        0.980\n            68          -0.11068        0.980\n            69          -0.10972        0.980\n            70          -0.10877        0.980\n            71          -0.10785        0.980\n            72          -0.10695        0.980\n            73          -0.10607        0.981\n            74          -0.10521        0.981\n            75          -0.10437        0.981\n            76          -0.10355        0.981\n            77          -0.10274        0.981\n            78          -0.10195        0.981\n            79          -0.10118        0.981\n            80          -0.10043        0.981\n            81          -0.09969        0.981\n            82          -0.09896        0.981\n            83          -0.09825        0.982\n            84          -0.09755        0.982\n            85          -0.09687        0.982\n            86          -0.09620        0.982\n            87          -0.09555        0.982\n            88          -0.09490        0.982\n            89          -0.09427        0.982\n            90          -0.09365        0.982\n            91          -0.09304        0.982\n            92          -0.09244        0.982\n            93          -0.09185        0.982\n            94          -0.09128        0.982\n            95          -0.09071        0.982\n            96          -0.09015        0.982\n            97          -0.08960        0.982\n            98          -0.08906        0.983\n            99          -0.08853        0.983\n         Final          -0.08801        0.983\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7925973197192087"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "import nltk\n",
    "def ExDialogFea(posts,i):\n",
    "    feature = {}\n",
    "    for word in nltk.word_tokenize(posts[i].text):\n",
    "        feature['contain {}'.format(word.lower())] = True\n",
    "    if i == 0 :\n",
    "        feature['prev tag'] = '<START>'\n",
    "    else:\n",
    "        feature['prev tag'] = posts[i-1].get('class')\n",
    "    return feature\n",
    "PostsFeaList = []\n",
    "posts = nps_chat.xml_posts()\n",
    "for i in range(len(posts)):\n",
    "    feature = ExDialogFea(posts,i)\n",
    "    PostsFeaList.append((feature,posts[i].get('class')))\n",
    "TrainSet,TestSet = PostsFeaList[:9000],PostsFeaList[9000:]\n",
    "PostClassifier = nltk.MaxentClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(PostClassifier,TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Word features can be very useful for performing document classification, since the words that appear in a document give a strong indication about what its semantic content is. However, many words occur very infrequently, and some of the most informative words in a document may never have occurred in our training data. One solution is to make use of a lexicon, which describes how different words relate to one another. Using WordNet lexicon, augment the movie review document classifier presented in this chapter to use features that generalize the words that appear in a document, making it more likely that they will match words found in the training data.\n",
    "#### 9. The PP Attachment Corpus is a corpus describing prepositional phrase attachment decisions. Each instance in the corpus is encoded as a `PPAttachment` object:\n",
    "```\n",
    "from nltk.corpus import ppattach\n",
    "ppattach.attachments('training')\n",
    "PPAttachment(sent='0', verb='join', noun1='board',\n",
    "              prep='as', noun2='director', attachment='V'),\n",
    "PPAttachment(sent='1', verb='is', noun1='chairman',\n",
    "              prep='of', noun2='N.V.', attachment='N'),\n",
    " ...]\n",
    "inst = ppattach.attachments('training')[1]\n",
    "(inst.noun1, inst.prep, inst.noun2)\n",
    "('chairman', 'of', 'N.V.')\n",
    "```\n",
    "Select only the instances where `inst.attachment` is `N`:\n",
    "```\n",
    "nattach = [inst for inst in ppattach.attachments('training')\n",
    "           if inst.attachment == 'N']\n",
    "```\n",
    "Using this sub-corpus, build a classifier that attempts to predict which preposition is used to connect a given pair of nouns. For example, given the pair of nouns \"team\" and \"researchers,\" the classifier should predict the preposition \"of\". See the corpus `HOWTO` at `http://nltk.org/howto` for more information on using the PP attachment corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==> Training (100 iterations)\n\n      Iteration    Log Likelihood    Accuracy\n      ---------------------------------------\n             1          -4.30407        0.003\n             2          -1.29282        0.799\n             3          -0.89499        0.838\n             4          -0.72269        0.850\n             5          -0.62480        0.859\n             6          -0.56096        0.864\n             7          -0.51566        0.869\n             8          -0.48163        0.872\n             9          -0.45499        0.874\n            10          -0.43348        0.876\n            11          -0.41568        0.878\n            12          -0.40066        0.879\n            13          -0.38779        0.880\n            14          -0.37662        0.881\n            15          -0.36680        0.882\n            16          -0.35809        0.883\n            17          -0.35030        0.884\n            18          -0.34328        0.884\n            19          -0.33692        0.885\n            20          -0.33112        0.885\n            21          -0.32580        0.886\n            22          -0.32090        0.887\n            23          -0.31637        0.887\n            24          -0.31216        0.888\n            25          -0.30825        0.888\n            26          -0.30459        0.888\n            27          -0.30116        0.889\n            28          -0.29794        0.889\n            29          -0.29491        0.889\n            30          -0.29204        0.890\n            31          -0.28933        0.890\n            32          -0.28676        0.890\n            33          -0.28432        0.891\n            34          -0.28200        0.891\n            35          -0.27979        0.891\n            36          -0.27768        0.891\n            37          -0.27567        0.892\n            38          -0.27374        0.892\n            39          -0.27189        0.893\n            40          -0.27011        0.893\n            41          -0.26841        0.893\n            42          -0.26677        0.893\n            43          -0.26519        0.894\n            44          -0.26368        0.894\n            45          -0.26221        0.894\n            46          -0.26080        0.894\n            47          -0.25943        0.894\n            48          -0.25811        0.894\n            49          -0.25683        0.894\n            50          -0.25559        0.895\n            51          -0.25440        0.894\n            52          -0.25323        0.895\n            53          -0.25211        0.895\n            54          -0.25101        0.895\n            55          -0.24995        0.895\n            56          -0.24891        0.895\n            57          -0.24791        0.896\n            58          -0.24693        0.896\n            59          -0.24598        0.896\n            60          -0.24505        0.896\n            61          -0.24414        0.896\n            62          -0.24326        0.896\n            63          -0.24240        0.896\n            64          -0.24156        0.896\n            65          -0.24074        0.896\n            66          -0.23994        0.896\n            67          -0.23916        0.896\n            68          -0.23840        0.897\n            69          -0.23765        0.897\n            70          -0.23692        0.897\n            71          -0.23621        0.897\n            72          -0.23551        0.897\n            73          -0.23482        0.897\n            74          -0.23415        0.897\n            75          -0.23349        0.897\n            76          -0.23285        0.897\n            77          -0.23222        0.898\n            78          -0.23160        0.898\n            79          -0.23099        0.898\n            80          -0.23040        0.898\n            81          -0.22981        0.898\n            82          -0.22924        0.898\n            83          -0.22868        0.898\n            84          -0.22812        0.898\n            85          -0.22758        0.898\n            86          -0.22705        0.898\n            87          -0.22652        0.898\n            88          -0.22600        0.898\n            89          -0.22550        0.899\n            90          -0.22500        0.899\n            91          -0.22451        0.899\n            92          -0.22403        0.899\n            93          -0.22355        0.899\n            94          -0.22309        0.899\n            95          -0.22263        0.899\n            96          -0.22217        0.899\n            97          -0.22173        0.899\n            98          -0.22129        0.899\n            99          -0.22086        0.899\n         Final          -0.22043        0.900\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'against'"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from nltk.corpus import ppattach\n",
    "def ExPPFea(instance):\n",
    "    feature = {\n",
    "        'noun1':instance.noun1, #['verb']:instance.verb,\n",
    "        'noun2':instance.noun2\n",
    "    }\n",
    "    return feature\n",
    "TrainSet = [(ExPPFea(i),i.prep) for i in ppattach.attachments('training') ]\n",
    "TestSet = [(ExPPFea(i),i.prep)  for i in ppattach.attachments('test') ]\n",
    "PPClassifer = nltk.MaxentClassifier.train(TrainSet)\n",
    "nltk.classify.accuracy(PPClassifer,TestSet)\n",
    "PPClassifer.classify({'noun1':'team',\n",
    "        'noun2':'reasearcher'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Suppose you wanted to automatically generate a prose description of a scene, and already had a word to uniquely describe each entity, such as the jar, and simply wanted to decide whether to use in or on in relating various items, e.g. the book is in the cupboard vs the book is on the shelf. Explore this issue by looking at corpus data; writing programs as needed.    \t\t\n",
    "##### a. in the car versus on the train\n",
    "##### b. in town versus on campus\n",
    "##### c. in the picture versus on the screen\n",
    "##### d. in Macbeth versus on Letterman"
   ]
  }
 ]
}