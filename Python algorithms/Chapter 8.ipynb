{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Algorithms\n",
    "## Chapter 8 Tangled Dependencies and Memoization\n",
    "Say you have a sequence of numbers, and you want to find its longest increasing (or, rather nondecreasing) subsequence—or one of them, if there are more. A subsequence consists of a subset of the elements in their original order. So, for example, in the sequence [3, 1, 0, 2, 4], one solution would be [1, 2, 4]\n",
    "### Don’t Repeat Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "def memo(func):\n",
    "    cache = {}\n",
    "    @wraps(func)\n",
    "    def wrap(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = func(*args)\n",
    "        return cache[args]\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we often think of the elements in order so that a single evaluation of $C(n,k)$ would only worry about whether element number $n$ should be included. If it is included, we have to count the $k-1$-sized subsets of the \n",
    "remaining $n-1$ elements, which is simply $C(n-1,k-1)$. If it is not included, we have to look for subsets of size $k$, or $C(n-1,k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@memo\n",
    "def C(n,k):\n",
    "    if k == 0: return 1\n",
    "    if n == 0: return 0\n",
    "    return C(n-1,k-1) + C(n-1,k)\n",
    "C(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "n,k = 10,7\n",
    "C = defaultdict(int)\n",
    "for row in range(n+1):\n",
    "    C[row,0] = 1\n",
    "    for col in range(1,k+1):\n",
    "        C[row,col] = C[row-1,col-1]+C[row-1,col]\n",
    "C[6,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Shortest Paths in Directed Acyclic Graphs\n",
    "At the core of dynamic programming lies the idea of sequential decision problems. Each choice you make leads to a \n",
    "new situation, and you need to find the best sequence of choices that gets you to the situation you want.  \n",
    "Let’s assume that we already know the answer for all the nodes we can move to. Let’s say the distance from a node $v$ to our end node is $d(v)$. Let the edge weight of edge $(u,v)$ be $w(u,v)$. Then, if we’re in node $u$, we already (by inductive hypothesis) know $d(v)$ for each neighbor $v$, so we just have to follow the edge to the neighbor $v$ that minimizes the expression $w(u,v) + d(v)$. In other words, we minimize the sum of the first step and the shortest path from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    'a':{'b':2,'f':9},\n",
    "    'b':{'c':1,'d':2,'f':6},\n",
    "    'c':{'d':7},\n",
    "    'd':{'e':2,'f':3},\n",
    "    'e':{'f':4},\n",
    "    'f':dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rec_short(G,s,t):\n",
    "    @memo\n",
    "    def d(u):\n",
    "        if u == t:\n",
    "            return 0\n",
    "        return min(G[u][v] + d(v) for v in G[u]) # min the sum of next step (from u to v) and from v to end point\n",
    "    return d(s)\n",
    "rec_short(G,'a','f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topsort(G):  # removing the correct node, linear time\n",
    "    count = dict((n,0) for n in G)\n",
    "    for n in G:\n",
    "        for v in G[n]:\n",
    "            count[v] += 1\n",
    "    Q = [n for n in G if count[n] ==0]\n",
    "    S = []\n",
    "    while Q:\n",
    "        a = Q.pop() # remove 0 in-degree\n",
    "        S.append(a)\n",
    "        for n in G[a]:\n",
    "            count[n] -= 1 # update count\n",
    "            if count[n] == 0:\n",
    "                Q.append(n)\n",
    "    return S\n",
    "topsort(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def itr_short(G,s,t):\n",
    "    d = {u:float('inf') for u in G} #initial estimate\n",
    "    d[s] = 0\n",
    "    for u in topsort(G):\n",
    "        if u == t:\n",
    "            break  #arrived at the destination\n",
    "        for v in G[u]:\n",
    "            d[v] = min(d[v],d[u] + G[u][v]) #update the last estimate with edge \n",
    "    return d[t]\n",
    "itr_short(G,'a','f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Increasing Subsequence\n",
    "Let’s try, to find the longest increasing subsequence that ends at each given position.If we’ve already know how to find this for the first $k$ positions, how can we find it for position $k + 1$? Once we’ve gotten this far, the answer is pretty straightforward: We just look at the previous positions and look at those whose elements are smaller than the current one. Among those, we choose the one that is at the end of the longest subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 16, 7, 20, 19, 1, 14, 16, 6, 7]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "n = [randint(0,20) for n in range(10)]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rec_ls(seq):\n",
    "    @memo \n",
    "    def ls(cur):\n",
    "        res = 1\n",
    "        for pre in range(cur):\n",
    "            if seq[pre] <= seq[cur]:\n",
    "                res = max(res,1+ls(pre)) \n",
    "        return res\n",
    "    return max(ls(i) for i in range(len(seq)))\n",
    "rec_ls(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def itr_ls(seq):\n",
    "    L = [1]*len(seq)\n",
    "    for curPos,val in enumerate(seq):\n",
    "        for prePos in range(curPos):\n",
    "            if seq[prePos] <= val:\n",
    "                L[curPos] = max(L[curPos],1+L[prePos])\n",
    "    return max(L)\n",
    "itr_ls(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Comparison\n",
    "Let’s say our sequences are $a$ and $b$. As with inductive thinking in general, we start with two arbitrary prefixes, identified by their lengths $i$ and $j$. What we need to do is relate the solution to this problem to some other problems, where at least one of the prefixes is smaller. Intuitively, we’d like to temporarily chop off some elements from the end of either sequence, solve the resulting problem by our inductive hypothesis, and stick the elements back on. If we stick with weak induction (reduction by one) along either sequence, we get three cases: Chop the last element from $a$, from $b$, or from both. If we remove an element from just one sequence, it’s excluded from the LCS. If we drop the last from both, however, what happens depends on whether the two elements are equal or not. If they are, we can use them to extend the LCS by one! (If not, they’re of no use to us.)\n",
    "We can express the length of the LCS of $a$ and $b$ as a function of prefix lengths $i$ and $j$ as follows:  \n",
    "$$\n",
    "L(i,j) = \\begin{cases}\n",
    "    0 &i = 0\\quad\\mathsf{or}\\quad j = 0  \\\\ \n",
    "    1 + L(i-1,j-1) & a_i = b_j \\\\\n",
    "    \\max(L(i-1,j),L(i,j-1))&\\mathsf{otherwise}\n",
    "\\end{cases}\n",
    "$$  \n",
    "![](../images/python%20algorithm/9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_lcs(a,b):\n",
    "    @memo\n",
    "    def L(i,j):\n",
    "        if min(i,j) < 0:\n",
    "            return 0\n",
    "        if a[i] == b[j]:\n",
    "            return 1 + L(i-1,j-1)\n",
    "        return max(L(i-1,j),L(i,j-1))\n",
    "    return L(len(a)-1,len(b)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'abcdefg'\n",
    "b = 'adcgifg'\n",
    "rec_lcs(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def itr_lcs(a,b):\n",
    "    n,m = len(a),len(b)\n",
    "    pre,cur = [0]*(n+1),[0]*(n+1)\n",
    "    for j in range(1,m+1):\n",
    "        pre,cur = cur,pre\n",
    "        for i in range(1,n+1):\n",
    "            if a[i-1] == b[j-1]:\n",
    "                cur[i] = pre[i-1] + 1\n",
    "            else:\n",
    "                cur[i] = max(pre[i],cur[i-1])\n",
    "    return cur[n]\n",
    "itr_lcs(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Knapsack Strikes Back\n",
    "If we say that $m(r)$ is the maximum value we can get with a (remaining) capacity $r$, each value of $r$ gives us a \n",
    "subproblem. The recursive decomposition is based on either using or not using the last unit of the capacity. If we don’t use it, we have $m(r) = m(r-1)$. If we do use it, we have to choose the right object to use. If we choose object $i$ (provided it will fit in the remaining capacity), we would have $m(r) = v[i] + m(r-w[i])$, because we’d add the value of $i$, but we’d also have used up a portion of the remaining capacity equal to its weight.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_unbound_knapsack(w,v,c): #weight, value, capacity\n",
    "    @memo\n",
    "    def m(r): #value of capacity r\n",
    "        if r ==0 :\n",
    "            return 0\n",
    "        val = m(r-1)\n",
    "        for i,weight in enumerate(w): #in all objects\n",
    "            if weight > r :\n",
    "                continue #too heavy\n",
    "            val = max(val,v[i] + m(r-weight))\n",
    "        return val\n",
    "    return m(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itr_unbound_knapsack(w,v,c):\n",
    "    m = [0]\n",
    "    for r in range(1,c+1):\n",
    "        val = m[r-1]\n",
    "        for i,weight in enumerate(w): #in all objects\n",
    "            if weight > r :\n",
    "                continue #too heavy\n",
    "            val = max(val,v[i] + m(r-weight))\n",
    "        m.append(val)\n",
    "    return m[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $m(k,r)$ be the maximum value we can have with the first k objects and a remaining capacity $r$. Then, clearly, if $k = 0$ or $r = 0$, we will have $m(k,r) = 0$. For other cases, we once again have to look at what our decision is. For this problem, the decision is simpler than in the unbounded one; we need consider only whether we want to include the last object, $i = k-1$. If we don’t, we will have $m(k,r) = m(k-1,r)$. In effect, we’re just “inheriting” the optimum from the case where we hadn’t considered $i$ yet. Note that if $w[i] > r$, we have no choice but to drop the object. If the object is small enough, though, we can include it, meaning that $m(k,r) = v[i] + m(k-1,r-w[i])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_knapsack(w,v,c):\n",
    "    @memo\n",
    "    def m(k,r):\n",
    "        if k ==0 or r == 0:\n",
    "            return 0\n",
    "        i = k-1\n",
    "        drop = m(k-1,r) # the optimal from the last one\n",
    "        if w[i] > r:\n",
    "            return drop\n",
    "        return max(drop,v[i] + m(k-1,r-w[i]))\n",
    "    return m(len(w),c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irt_knapsack(w,v,c):\n",
    "    n = len(w)\n",
    "    m = [[0]*(c+1) for i in range(n+1)] #max/value\n",
    "    P = [[False]*(c+1) for i in range(n+1)] # drop/include\n",
    "    for k in range(1,n+1):\n",
    "        i = k-1\n",
    "        for r in range(1,k+1):\n",
    "            m[k][r] = drop = m[k-1][r]\n",
    "            if w[i] > r:\n",
    "                continue\n",
    "            keep = v[i]+m[k-1][r-w[i]]\n",
    "            m[k][r] = max(drop,keep)\n",
    "            P[k][r] = keep > drop\n",
    "    return m,P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Sequence Partitioning\n",
    "### Exercise\n",
    "1. Rewrite `@memo` so that you reduce the number of dict lookups by one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "def memo2(func):\n",
    "    cache = {}\n",
    "    @wraps(func)\n",
    "    def wrap(*args):\n",
    "        try:\n",
    "            cache[args] = func(*args)\n",
    "            return cache[args]\n",
    "        except:\n",
    "            pass\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How can `two_pow` be seen as using the “in or out” idea? What would the “in or out” correspond to?   \n",
    "    Counting subsets\n",
    "3. Write iterative versions of `fib` and `two_pow`. This should allow you to use a constant amount of memory, while retaining the pseudolinear time (that is, time linear in the parameter `n`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def itr_fib(i):\n",
    "    num = [1,1]\n",
    "    if i == 0 or i == 1:\n",
    "        return num[i]\n",
    "    for j in range(2,i+1):\n",
    "        num.append(num[j-1] + num[j-2])\n",
    "    return num[-1]\n",
    "itr_fib(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The code for computing Pascal’s triangle in this chapter actually fills out an rectangle, where the irrelevant parts are simply zeros. Rewrite the code to avoid this redundancy.\n",
    "5. Extend either the recursive or iterative code for finding the length of the shortest path in a DAG so that it returns an actual optimal path.    \n",
    "   store the choice made in each node. \n",
    "6. Why won’t the pruning discussed in the sidebar “Varieties of DAG Shortest Path” have any effect \n",
    "on the asymptotic running time, even in the best case?     \n",
    "   toplogical sorting will have to visit every node. \n",
    "7. In the object-oriented `observer` pattern, several observers may register with an observable object. These observers are then notified when the observable changes. How could this idea be used to implement the DP solution to the DAG shortest path problem? How would it be similar to or different from the approaches discussed in this chapter?    \n",
    "   let each node observe its predecessors and then explicitly trigger an update in the estimate in the start node. The observers would be notified of changes and could update their own estimates accordingly, triggering new updates in their observers\n",
    "8. In the `lis` function, how do we know that `end` is nondecreasing?   \n",
    "   each objected is added by bisect, making the list sorted. \n",
    "9. How would you reduce the number of calls to `bisect` in `lis`?   \n",
    "   check if the new element is larger than the last element or if end is empty\n",
    "10. Extend either the recursive or one of the iterative solutions to the longest increasing subsequence problem so that it returns the actual subsequence.    \n",
    "    remember the predecessors \n",
    "11. Implement a function that computes the edit distance between two sequences, either using \n",
    "memoization or using iterative DP.\n",
    "12. How would you find the underlying structure for LCS (that is, the actual shared subsequence) or \n",
    "edit distance (the sequence of edit operations)?   \n",
    "    keep track of the choices  \n",
    "13. If the two sequences compared in `lcs` have different lengths, how could you exploit that to \n",
    "reduce the function’s memory use?   \n",
    "    swap the sequence and length  \n",
    "14. How could you modify $w$ and $c$ to (potentially) reduce the running time of the unbounded \n",
    "knapsack problem?    \n",
    "    divide by greatest common diviser  \n",
    "15. The knapsack solution in Listing 8-13 lets you find the actual elements included in the optimal \n",
    "solution. Extend one of the other knapsack solutions in a similar way.  \n",
    "16. How can it be that we have developed efficient solutions to the integer knapsack problems, when \n",
    "they are regarded as hard, unsolved problems (see Chapter 11)?     \n",
    "     The running time is pseudopolynomial\n",
    "17. The subset sum problem is one you’ll also see in Chapter 11. Briefly, it asks you to pick a subset of a set of integers so that the sum of the subset is equal to a given constant, $k$. Implement a solution to this problem based on dynamic programming.   \n",
    "18. A problem closely related to finding optimal binary search trees is the matrix chain \n",
    "multiplication problem, briefly mentioned in the text. If matrices A and B have dimensions n×m and \n",
    "m×p, respectively, their product AB will have dimensions n×p, and we approximate the cost of this \n",
    "multiplication by the product nmp (the number of element multiplications). Design and implement \n",
    "an algorithm that finds a parenthetization of a sequence of matrices so that performing all the matrix multiplications has as low total cost as possible.   \n",
    "19. The optimal search trees we construct are based only on the frequencies of the elements. We \n",
    "might also want to take into account the frequencies of various queries that are not in the search tree. For example, we could have the frequencies for all words in a language available but store only some of the words in the tree. How could you take this information into consideration?\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b67a93151de190f6cc8f9707f54bafc2958bf8bfaa7d847c8c4b5621a84335b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
