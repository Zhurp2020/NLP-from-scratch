{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Algorithms\n",
    "## Chapter 9 From A to B with Edsger and Friends\n",
    "### Propagating Knowledge\n",
    "### Relaxing like Crazy\n",
    "After k rounds of relaxing every edge in the graph, we know that all shortest paths of consisting of k edges have been completed. Following our earlier reasoning, for a graph with n nodes and m edges, \n",
    "it will require at most n-1 rounds until we’re done, giving us a running time of $\\Theta(nm)$. Of course, this need only be the worst-case running time, if we add a check: Has anything changed in the last round? If nothing changed, there’s no point in continuing. We might even be tempted to drop the whole n-1 count and only rely on this check. After all, we’ve just reasoned that we’ll never need more than n-1 rounds, so the check will eventually halt the algorithm.   \n",
    "If we have no negative cycles, the “no change” condition will work just fine, but throw in a negative cycle, and our estimates can keep improving forever. So ... as long as we allow negative edges (and why wouldn’t we?), we need the iteration count as a safeguard. \n",
    "### Finding the Hidden DAG\n",
    "### All Against All\n",
    "When solving the all-pairs shortest paths problem for sparse graphs, simply using Dijkstra’s algorithm from every node is, in fact, a really good solution. That in itself doesn’t exactly motivate a new algorithm ... but the trouble is that Dijkstra’s algorithm doesn’t permit negative edges. For the single-source shortest path problem, there isn’t much we can do about that, except use Bellman-Ford instead. For the all-pairs problem, though, we can permit ourselves some initial preprocessing to make all the weights positive.  \n",
    "The idea is to add a new node s, with zero-weight edges to all existing nodes, and then to run Bellman-Ford from \n",
    "s. This will give us a distance—let’s call it h(v)—from s to each node v in our graph. We can then use h to adjust the weight of every edge: We define the new weight as follows: w’(u,v) = w(u,v) + h(u) - h(v). This definition has two very useful properties. First, it guarantees us that every new weight w’(u,v) is nonnegative (this follows from the triangle inequality). Second, we’re not messing up our problem! That is, if we find the shortest paths with these new weights, those paths will also be shortest paths (with other lengths, though) with the original weights. \n",
    "### Far-Fetched Subproblems\n",
    "We arbitrarily order the nodes and restrict how many—that is, the k first—we’re allowed to use as intermediate nodes in forming our paths. We have now parametrized our subproblems using three parameters:\n",
    "+ The starting node\n",
    "+ The ending node\n",
    "+ The highest node number we’re allowed to pass through  \n",
    "\n",
    "Let $d(u, v,k)$ be the length of the shortest path that exists from node u to node v if you’re only allowed to use the $k$ first nodes as intermediate nodes. We can decompose the problem as follows:\n",
    "$$\n",
    "d(u, v, k) = \\min(d(u, v,k−1), d(u,k,k−1) + d(k, v,k−1))\n",
    "$$\n",
    "### Meeting in the Middle\n",
    "### Knowing Where You’re Going\n",
    "In A*, we want to modify the edges in a similar fashion, but this time the goal isn’t to make the \n",
    "edges positive—we’re assuming they already are (as we’re building on Dijkstra’s algorithm). No, what we want is to guide the traversal in the right direction, by using information of where we’re going: We want to make edges moving away from our target node more expensive than those that take us closer to it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
