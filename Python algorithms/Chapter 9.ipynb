{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Algorithms\n",
    "## Chapter 9 From A to B with Edsger and Friends\n",
    "### Propagating Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e, f, g, h = list(range(8))\n",
    "G = {\n",
    " a: {b:2, c:1, d:3, e:9, f:4},\n",
    " b: {c:4, e:3},\n",
    " c: {d:8},\n",
    " d: {e:7},\n",
    " e: {f:5},\n",
    " f: {c:2, g:2, h:2},\n",
    " g: {f:1, h:6},\n",
    " h: {f:9, g:8}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = float('inf')\n",
    "def relax(Graph, start, end, estimate:dict, parent):\n",
    "    update = estimate.get(start,inf) + Graph[start][end] # a possible better path, current estimate to start and a path to end\n",
    "    if update < estimate.get(end,inf): # really better?\n",
    "        estimate[end], parent[end] = update, start\n",
    "        return True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relaxing like Crazy\n",
    "After k rounds of relaxing every edge in the graph, we know that all shortest paths of consisting of k edges have been completed. Following our earlier reasoning, for a graph with n nodes and m edges, \n",
    "it will require at most n-1 rounds until we’re done, giving us a running time of $\\Theta(nm)$. Of course, this need only be the worst-case running time, if we add a check: Has anything changed in the last round? If nothing changed, there’s no point in continuing. We might even be tempted to drop the whole n-1 count and only rely on this check. After all, we’ve just reasoned that we’ll never need more than n-1 rounds, so the check will eventually halt the algorithm.   \n",
    "If we have no negative cycles, the “no change” condition will work just fine, but throw in a negative cycle, and our estimates can keep improving forever. So ... as long as we allow negative edges (and why wouldn’t we?), we need the iteration count as a safeguard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 2, 2: 1, 3: 3, 4: 5, 5: 4, 6: 6, 7: 6},\n",
       " {1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 5, 7: 5})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def BellmanFord(G,s):\n",
    "    estimate,parent = {s:0},{}\n",
    "    for round in G:\n",
    "        change = False\n",
    "        for start in G:  #len(G) rounds\n",
    "            for end in G[start]:\n",
    "                if relax(G,start,end,estimate,parent):\n",
    "                    change = True\n",
    "        if not change:\n",
    "                break\n",
    "    else:\n",
    "        raise ValueError('negative cycle')\n",
    "    return estimate,parent\n",
    "BellmanFord(G,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Hidden DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 2, 2: 1, 3: 3, 4: 5, 5: 4, 6: 6, 7: 6},\n",
       " {1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 5, 7: 5})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import heappush, heappop\n",
    "def dijkstra(G,s):\n",
    "    estimate, tree, queue, visited = {s:0}, {}, [(0,s)],set()\n",
    "    while queue:\n",
    "        _,u = heappop(queue)\n",
    "        if u in visited:\n",
    "            continue\n",
    "        visited.add(u)\n",
    "        for v in G[u]:\n",
    "            relax(G,u,v,estimate,tree)\n",
    "            heappush(queue,(estimate[v],v))\n",
    "    return estimate,tree\n",
    "dijkstra(G,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Against All\n",
    "When solving the all-pairs shortest paths problem for sparse graphs, simply using Dijkstra’s algorithm from every node is, in fact, a really good solution. That in itself doesn’t exactly motivate a new algorithm ... but the trouble is that Dijkstra’s algorithm doesn’t permit negative edges. For the single-source shortest path problem, there isn’t much we can do about that, except use Bellman-Ford instead. For the all-pairs problem, though, we can permit ourselves some initial preprocessing to make all the weights positive.  \n",
    "The idea is to add a new node s, with zero-weight edges to all existing nodes, and then to run Bellman-Ford from \n",
    "s. This will give us a distance—let’s call it h(v)—from s to each node v in our graph. We can then use h to adjust the weight of every edge: We define the new weight as follows: w’(u,v) = w(u,v) + h(u) - h(v). This definition has two very useful properties. First, it guarantees us that every new weight w’(u,v) is nonnegative (this follows from the triangle inequality). Second, we’re not messing up our problem! That is, if we find the shortest paths with these new weights, those paths will also be shortest paths (with other lengths, though) with the original weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: {0: 0, 1: 2, 2: 1, 3: 3, 4: 5, 5: 4, 6: 6, 7: 6},\n",
       "  1: {1: 0, 2: 4, 4: 3, 5: 8, 3: 12, 6: 10, 7: 10},\n",
       "  2: {2: 0, 3: 8, 4: 15, 5: 20, 6: 22, 7: 22},\n",
       "  3: {3: 0, 4: 7, 5: 12, 2: 14, 6: 14, 7: 14},\n",
       "  4: {4: 0, 5: 5, 2: 7, 6: 7, 7: 7, 3: 15},\n",
       "  5: {5: 0, 2: 2, 6: 2, 7: 2, 3: 10, 4: 17},\n",
       "  6: {6: 0, 5: 1, 7: 3, 2: 3, 3: 11, 4: 18},\n",
       "  7: {7: 0, 5: 9, 6: 8, 2: 11, 3: 19, 4: 26}},\n",
       " {0: {1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 5, 7: 5},\n",
       "  1: {2: 1, 4: 1, 5: 4, 3: 2, 6: 5, 7: 5},\n",
       "  2: {3: 2, 4: 3, 5: 4, 6: 5, 7: 5},\n",
       "  3: {4: 3, 5: 4, 2: 5, 6: 5, 7: 5},\n",
       "  4: {5: 4, 2: 5, 6: 5, 7: 5, 3: 2},\n",
       "  5: {2: 5, 6: 5, 7: 5, 3: 2, 4: 3},\n",
       "  6: {5: 6, 7: 5, 2: 5, 3: 2, 4: 3},\n",
       "  7: {5: 7, 6: 7, 2: 5, 3: 2, 4: 3}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "def johnson(G):\n",
    "    G = deepcopy(G)\n",
    "    s = object()\n",
    "    G[s] = {v:0 for v in G}\n",
    "    h,_ = BellmanFord(G,s)\n",
    "    del G[s]\n",
    "    for start in G:\n",
    "        for end in G[start]:\n",
    "            G[start][end] += h[start] - h[end]\n",
    "    estimate,parent = {},{}\n",
    "    for start in G:\n",
    "        estimate[start],parent[start] = dijkstra(G,start)\n",
    "        for end in G[start]:\n",
    "            estimate[start][end] += h[end] - h[start]\n",
    "    return estimate,parent\n",
    "johnson(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Far-Fetched Subproblems\n",
    "We arbitrarily order the nodes and restrict how many—that is, the k first—we’re allowed to use as intermediate nodes in forming our paths. We have now parametrized our subproblems using three parameters:\n",
    "+ The starting node\n",
    "+ The ending node\n",
    "+ The highest node number we’re allowed to pass through  \n",
    "\n",
    "Let $d(u, v,k)$ be the length of the shortest path that exists from node u to node v if you’re only allowed to use the $k$ first nodes as intermediate nodes. We can decompose the problem as follows:\n",
    "$$\n",
    "d(u, v, k) = \\min(d(u, v,k−1), d(u,k,k−1) + d(k, v,k−1))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "def memo(func):\n",
    "    cache = {}\n",
    "    @wraps(func)\n",
    "    def wrap(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = func(*args)\n",
    "        return cache[args]\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_floyd(G):\n",
    "    @memo\n",
    "    def d(u,v,k):\n",
    "        if k == 0:\n",
    "            return G[u][v]\n",
    "        return min(d(u,v,k-1),d(u,k,k-1)+d(k,v,k-1))\n",
    "    return {(u,v):d(u,v,len(G)) for u in G for v in G}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itr_floyd(G):\n",
    "    D = deepcopy(G)\n",
    "    for k in G:\n",
    "        for u in G:\n",
    "            for v in G:\n",
    "                D[u][v] = min(D[u][v],D[u][k] + D[k][v])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Meeting in the Middle\n",
    "### Knowing Where You’re Going\n",
    "In A*, we want to modify the edges in a similar fashion, but this time the goal isn’t to make the \n",
    "edges positive—we’re assuming they already are (as we’re building on Dijkstra’s algorithm). No, what we want is to guide the traversal in the right direction, by using information of where we’re going: We want to make edges moving away from our target node more expensive than those that take us closer to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop,heappush\n",
    "def a_star(G,s,t,h):\n",
    "    P,Q = {},[(h(s),None,s)]\n",
    "    while Q:\n",
    "        d,p,u = heappop(Q)\n",
    "        if u in P:\n",
    "            continue\n",
    "        P[u] = p\n",
    "        if u == t:\n",
    "            return d-h(t),P\n",
    "        for v in G[u]:\n",
    "            w = G[u][v] - h(u) + h(v)\n",
    "            heappush(Q,(d+w,u,v))\n",
    "    return inf,None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "1. In some cases, discrepancies in exchange rates between currencies make it possible to exchange from one currency to another, continuing until one gets back to the original, having made a profit. How would you use the Bellman-Ford algorithm to detect the presence of such a situation?    \n",
    "   You have to somehow modify the algorithm or the graph so the detection mechanism for negative additive \n",
    "cycles can be used to find multiplicative cycles where the product of the exchange rates ends up above 1. The easiest solution is to simply take transform all the weights by taking their logarithms and negating them. \n",
    "2. What happens in Dijkstra’s algorithm if more than one node has the same distance from the start \n",
    "node? Is it still correct?   \n",
    "   It does not matter\n",
    "3. Why is it a really bad idea to represent edge length using dummy nodes, like in Figure 9-3?  \n",
    "   pseudopolynomial running time\n",
    "4. What would the running time of Dijkstra’s algorithm be if you implemented it with an unsorted list \n",
    "instead of a binary heap?  \n",
    "   It could be done in constant time\n",
    "5. Why can we be certain that the adjusted weights in Johnson’s algorithm are nonnegative? Are \n",
    "there cases where things can go wrong?   \n",
    "   If there are negative cycles, the bellman ford will detect it. \n",
    "6. In Johnson’s algorithm, the h function is based on the Bellman-Ford algorithm. Why can’t we just use an arbitrary function here? It would disappear in the telescoping sum anyway?   \n",
    "   We can't guarantee nonnegative weights. \n",
    "7. Implement the memoized version of Floyd-Warshall so it saves memory in the same way as the iterative one.\n",
    "8. Extend the memoized version of Floyd-Warshall to compute a P table, just like the iterative one.\n",
    "9. How would you modify the Floyd-Warshall algorithm so it detects the presence of paths, rather than finding the shortest paths (Warshall’s algorithm)?\n",
    "10. Why does correctness for the tighter stopping criterion for the bidirectional version of Dijkstra’s \n",
    "algorithm imply correctness for the original?\n",
    "11. In the correctness proof for the bidirectional version of Dijkstra’s algorithm, I posited a hypothetical path that would be shorter than the best one we’d found so far and stated that it had to contain an edge (u,v) such that d(s,u) < l and d(v,t) < r. Why is this the case?\n",
    "12. Rewrite bidir_dijkstra so it doesn’t require the input graph to be symmetric, with zero-weight \n",
    "self-edges.\n",
    "13. Implement a bidirectional version of BFS.\n",
    "14. Why is h(v) a lower bound on d(v,t) when w’ is feasible?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b67a93151de190f6cc8f9707f54bafc2958bf8bfaa7d847c8c4b5621a84335b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
